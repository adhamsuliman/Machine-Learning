{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in c:\\users\\u353822\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (0.81)\n",
      "Requirement already satisfied: scipy in c:\\users\\u353822\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from xgboost) (1.0.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\u353822\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from xgboost) (1.14.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using pip version 18.1, however version 19.0.2 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install  xgboost\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix, classification_report\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.grid_search import GridSearchCV, RandomizedSearchCV\n",
    "import pickle\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Processing:\n",
    "#a) Import the data from the website directly\n",
    "adult_df = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data', header = None, skipinitialspace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32561, 15)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_columns = [\"age\", \"workclass\", \"fnlwgt\", \"education\", \"education_num\", \"marital_status\", \"occupation\", \"relationship\", \"race\", \"sex\", \"capital_gain\", \"capital_loss\", \"hours_per_week\", \"native_country\",\"salary\"]\n",
    "adult_df.columns = list_of_columns\n",
    "adult_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "adult_df = adult_df.drop(['fnlwgt'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>education</th>\n",
       "      <th>education_num</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital_gain</th>\n",
       "      <th>capital_loss</th>\n",
       "      <th>hours_per_week</th>\n",
       "      <th>native_country</th>\n",
       "      <th>salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age         workclass  education  education_num      marital_status  \\\n",
       "0   39         State-gov  Bachelors             13       Never-married   \n",
       "1   50  Self-emp-not-inc  Bachelors             13  Married-civ-spouse   \n",
       "2   38           Private    HS-grad              9            Divorced   \n",
       "3   53           Private       11th              7  Married-civ-spouse   \n",
       "4   28           Private  Bachelors             13  Married-civ-spouse   \n",
       "\n",
       "          occupation   relationship   race     sex  capital_gain  \\\n",
       "0       Adm-clerical  Not-in-family  White    Male          2174   \n",
       "1    Exec-managerial        Husband  White    Male             0   \n",
       "2  Handlers-cleaners  Not-in-family  White    Male             0   \n",
       "3  Handlers-cleaners        Husband  Black    Male             0   \n",
       "4     Prof-specialty           Wife  Black  Female             0   \n",
       "\n",
       "   capital_loss  hours_per_week native_country  salary  \n",
       "0             0              40  United-States       0  \n",
       "1             0              13  United-States       0  \n",
       "2             0              40  United-States       0  \n",
       "3             0              40  United-States       0  \n",
       "4             0              40           Cuba       0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adult_df.salary = adult_df.salary.replace(\">50K\",1)\n",
    "adult_df.salary = adult_df.salary.replace(\"<=50K\",0)\n",
    "adult_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32561, 13)\n",
      "(32561,)\n"
     ]
    }
   ],
   "source": [
    "X = adult_df.iloc[:,:-1]\n",
    "print(X.shape)\n",
    "y = adult_df.iloc[:,-1]\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_encoded = pd.get_dummies(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#d) Split data into train / test set using an 70/30 split. Recall that you should be generating an X_train, X_test, y_train, and y_test.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=3, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#2) Random Forest Classifier - Base Model:\n",
    "#a Use the RandomForestClassifier in sklearn. \n",
    "clf = RandomForestClassifier(random_state=3)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1]\n",
      "[0.         0.01       0.01428571 0.01666667 0.01818182 0.02\n",
      " 0.02142857 0.025      0.02857143 0.03333333 0.03611111 0.04\n",
      " 0.04583333 0.04928571 0.05       0.05444444 0.05714286 0.06\n",
      " 0.0625     0.065      0.06666667 0.06857143 0.06966153 0.07\n",
      " 0.07142857 0.07440476 0.075      0.08       0.08333333 0.08333333\n",
      " 0.08948524 0.09166667 0.095      0.09833333 0.1        0.10496032\n",
      " 0.10690476 0.10833333 0.11178571 0.1125     0.11274725 0.11328671\n",
      " 0.11428571 0.11619048 0.11666667 0.1175     0.12       0.1202381\n",
      " 0.12166667 0.125      0.12504329 0.12857143 0.13068182 0.13095238\n",
      " 0.13166667 0.1325     0.13320818 0.13333333 0.13729659 0.14\n",
      " 0.14489177 0.14545455 0.15       0.15467033 0.15833333 0.16\n",
      " 0.16111111 0.1625     0.16666667 0.16722222 0.17142857 0.175\n",
      " 0.18       0.18166667 0.18270202 0.18333333 0.18333333 0.18452381\n",
      " 0.18666667 0.1875     0.18761905 0.18791486 0.18857143 0.19069114\n",
      " 0.19111111 0.19166667 0.195      0.19583333 0.19893218 0.19904762\n",
      " 0.19941392 0.2        0.20333333 0.21       0.21190476 0.21297619\n",
      " 0.21428571 0.215      0.21662698 0.21666667 0.21666667 0.22\n",
      " 0.22471306 0.22489177 0.225      0.22619048 0.22666667 0.22857143\n",
      " 0.23166667 0.23222222 0.23333333 0.23333333 0.23599567 0.23809524\n",
      " 0.23833333 0.2384127  0.24       0.24166667 0.24285714 0.245\n",
      " 0.2452381  0.2452886  0.24690045 0.25       0.25333333 0.25630952\n",
      " 0.2625     0.26488095 0.265      0.26507937 0.26666667 0.26666667\n",
      " 0.26785714 0.275      0.27833333 0.28       0.28166667 0.28333333\n",
      " 0.285      0.28527778 0.28642857 0.28809524 0.28833333 0.29\n",
      " 0.29166667 0.29214286 0.29227717 0.29333333 0.2952381  0.29666667\n",
      " 0.3        0.3        0.3075     0.30833333 0.30833333 0.30857143\n",
      " 0.30952381 0.31       0.31333333 0.31412698 0.31428571 0.31655413\n",
      " 0.31666667 0.31944444 0.32       0.32       0.325      0.32833333\n",
      " 0.32904762 0.3297619  0.33       0.33047619 0.33214286 0.3325\n",
      " 0.33333333 0.33333333 0.33666667 0.3375     0.33833333 0.33846154\n",
      " 0.33928571 0.34       0.34166667 0.34333333 0.34467121 0.34904762\n",
      " 0.34952381 0.35       0.35238095 0.35547619 0.35833333 0.36\n",
      " 0.36151515 0.365      0.36666667 0.36666667 0.36746032 0.375\n",
      " 0.37666667 0.37678571 0.37714286 0.38       0.38333333 0.38333333\n",
      " 0.385      0.385      0.38571429 0.39       0.39166667 0.39242063\n",
      " 0.39333333 0.39452381 0.395      0.39715368 0.39833333 0.39880952\n",
      " 0.4        0.40067599 0.40708791 0.40833333 0.40833333 0.41\n",
      " 0.41333333 0.415      0.41666667 0.41666667 0.42       0.42\n",
      " 0.4227381  0.42416667 0.42452381 0.425      0.43       0.43333333\n",
      " 0.43333333 0.435      0.4352381  0.43666667 0.43699634 0.4375\n",
      " 0.43847958 0.44       0.44166667 0.44166667 0.44583333 0.44833333\n",
      " 0.44869048 0.45       0.45666667 0.45714286 0.45833333 0.46\n",
      " 0.4602381  0.46071429 0.46166667 0.46300366 0.4633178  0.465\n",
      " 0.46553571 0.46666667 0.46666667 0.46936508 0.47       0.47166667\n",
      " 0.47287879 0.47333333 0.475      0.47547619 0.47699301 0.47988262\n",
      " 0.48       0.48055556 0.48119048 0.48166667 0.48333333 0.48333333\n",
      " 0.48375458 0.48666667 0.48781926 0.48888889 0.49       0.49090909\n",
      " 0.49166667 0.495      0.5        0.505      0.50833333 0.50833333\n",
      " 0.50909091 0.51       0.51111111 0.51218074 0.51333333 0.51624542\n",
      " 0.51666667 0.51666667 0.51833333 0.51880952 0.51944444 0.52\n",
      " 0.52011738 0.52300699 0.52452381 0.525      0.52666667 0.52712121\n",
      " 0.52833333 0.53       0.53063492 0.53333333 0.53333333 0.53446429\n",
      " 0.535      0.5366822  0.53699634 0.53833333 0.53928571 0.5397619\n",
      " 0.54       0.54       0.54166667 0.54285714 0.54333333 0.55\n",
      " 0.55       0.55130952 0.55166667 0.55416667 0.55833333 0.56\n",
      " 0.56152042 0.5625     0.56300366 0.56333333 0.5647619  0.565\n",
      " 0.56666667 0.57       0.575      0.57547619 0.57583333 0.5772619\n",
      " 0.58       0.58       0.58333333 0.58333333 0.585      0.58666667\n",
      " 0.59       0.59166667 0.59166667 0.59291209 0.59932401 0.6\n",
      " 0.60119048 0.60166667 0.60284632 0.605      0.60547619 0.60666667\n",
      " 0.60757937 0.60833333 0.61       0.61428571 0.615      0.61666667\n",
      " 0.61666667 0.62       0.62285714 0.62321429 0.62333333 0.625\n",
      " 0.63253968 0.63333333 0.635      0.63848485 0.64       0.64\n",
      " 0.64166667 0.64452381 0.64761905 0.65       0.65047619 0.65095238\n",
      " 0.65532879 0.65666667 0.65833333 0.66       0.66071429 0.66153846\n",
      " 0.66166667 0.6625     0.66333333 0.66666667 0.66666667 0.6675\n",
      " 0.66785714 0.66952381 0.67       0.6702381  0.67095238 0.67166667\n",
      " 0.675      0.68       0.68055556 0.68333333 0.68344587 0.68571429\n",
      " 0.68587302 0.68666667 0.69       0.69047619 0.69142857 0.69166667\n",
      " 0.6925     0.7        0.70333333 0.7047619  0.70666667 0.70772283\n",
      " 0.70785714 0.70833333 0.71       0.71166667 0.71190476 0.71357143\n",
      " 0.71472222 0.715      0.71666667 0.71666667 0.71833333 0.72\n",
      " 0.72166667 0.725      0.73214286 0.73333333 0.73333333 0.73492063\n",
      " 0.735      0.73511905 0.7375     0.74369048 0.74666667 0.75\n",
      " 0.75       0.75309955 0.7547114  0.7547619  0.755      0.75714286\n",
      " 0.75833333 0.76       0.7615873  0.76166667 0.76190476 0.76400433\n",
      " 0.76666667 0.76666667 0.76777778 0.76833333 0.77142857 0.77333333\n",
      " 0.77380952 0.775      0.77510823 0.77528694 0.78       0.78333333\n",
      " 0.78337302 0.785      0.78571429 0.78702381 0.78809524 0.79\n",
      " 0.79666667 0.8        0.80058608 0.80095238 0.80106782 0.80416667\n",
      " 0.805      0.80833333 0.80888889 0.80930886 0.81142857 0.81208514\n",
      " 0.81238095 0.8125     0.81333333 0.81547619 0.81666667 0.81666667\n",
      " 0.81729798 0.81833333 0.82       0.825      0.82857143 0.83277778\n",
      " 0.83333333 0.83333333 0.8375     0.83888889 0.84       0.84166667\n",
      " 0.84166667 0.84532967 0.85       0.85454545 0.85510823 0.86\n",
      " 0.86270341 0.86666667 0.86666667 0.86679182 0.8675     0.86833333\n",
      " 0.86904762 0.86931818 0.87142857 0.87495671 0.875      0.87833333\n",
      " 0.8797619  0.88       0.8825     0.88333333 0.88380952 0.88571429\n",
      " 0.88671329 0.88725275 0.8875     0.88821429 0.89166667 0.89309524\n",
      " 0.89503968 0.9        0.90166667 0.905      0.90833333 0.90833333\n",
      " 0.91051476 0.91666667 0.91666667 0.92       0.925      0.92559524\n",
      " 0.92857143 0.93       0.93033847 0.93142857 0.93333333 0.93333333\n",
      " 0.935      0.9375     0.94       0.94285714 0.94555556 0.95\n",
      " 0.95071429 0.95416667 0.96       0.96388889 0.96666667 0.96666667\n",
      " 0.97142857 0.975      0.97857143 0.98       0.98181818 0.98333333\n",
      " 0.98571429 0.99       1.        ]\n"
     ]
    }
   ],
   "source": [
    "#2) Random Forest Classifier - Base Model:\n",
    "#b Use the fitted model to predict on test data. Use the .predict_proba() and the .predict() methods to get predicted probabilities as well as predicted classes.\n",
    "y_pred = clf.predict(X_test)\n",
    "print(np.unique(y_pred))\n",
    "print(np.unique(clf.predict_proba(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6844  611]\n",
      " [ 925 1389]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.92      0.90      7455\n",
      "          1       0.69      0.60      0.64      2314\n",
      "\n",
      "avg / total       0.84      0.84      0.84      9769\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#c) Calculate the confusion matrix and classification report (both are in sklearn.metrics). These are the same tools from HW #3.\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test,y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7591504370504212\n"
     ]
    }
   ],
   "source": [
    "#d) Calculate the roc_auc_score for this model. There are many ways to do this, but an example is to use the probabilities from step B and utilize the roc_auc_score from sklearn.\n",
    "y_pred = clf.predict(X_test)\n",
    "print(roc_auc_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>0.231459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hours_per_week</th>\n",
       "      <td>0.110898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>capital_gain</th>\n",
       "      <td>0.109006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>education_num</th>\n",
       "      <td>0.070090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>marital_status_Married-civ-spouse</th>\n",
       "      <td>0.065040</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   importance\n",
       "age                                  0.231459\n",
       "hours_per_week                       0.110898\n",
       "capital_gain                         0.109006\n",
       "education_num                        0.070090\n",
       "marital_status_Married-civ-spouse    0.065040"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#e) Identify the top 5 features:\n",
    "pd.DataFrame(clf.feature_importances_,index = X_train.columns,\n",
    "        columns=['importance']).sort_values('importance',ascending=False).iloc[:5,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.99      0.98     17265\n",
      "          1       0.96      0.91      0.93      5527\n",
      "\n",
      "avg / total       0.97      0.97      0.97     22792\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#f) \n",
    "y_pred_train = clf.predict(X_train)\n",
    "print(classification_report(y_train,y_pred_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is there overfitting?\n",
    "Yes there is overfitting because we gett an avg accuracy of 97% for our training data while we get an average accuracy of 84% on our test data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
       "          learning_rate=1.0, n_estimators=50, random_state=None),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'n_estimators': [100, 200, 300, 400], 'learning_rate': [0.2, 0.4, 0.6, 0.8, 1, 1.2], 'random_state': [0]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring='roc_auc', verbose=0)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Part 3 \n",
    "#a)\n",
    "clf = RandomForestClassifier()\n",
    "ABC = AdaBoostClassifier()\n",
    "param_grid = {'n_estimators':[100, 200,300,400],\n",
    "'learning_rate':[0.2,0.4,0.6,0.8,1, 1.2],\n",
    "'random_state':[0]}\n",
    "\n",
    "RF_Grid = GridSearchCV(ABC, param_grid=param_grid, scoring='roc_auc', cv=5)\n",
    "RF_Grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1]\n",
      "[0.4664587  0.46717852 0.46983509 ... 0.53016491 0.53282148 0.5335413 ]\n"
     ]
    }
   ],
   "source": [
    "#b Use the fitted model to predict on test data. Use the .predict_proba() and the .predict() methods to get predicted probabilities as well as predicted classes.\n",
    "y_pred = RF_Grid.predict(X_test)\n",
    "print(np.unique(y_pred))\n",
    "print(np.unique(RF_Grid.predict_proba(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7008  447]\n",
      " [ 807 1507]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.94      0.92      7455\n",
      "          1       0.77      0.65      0.71      2314\n",
      "\n",
      "avg / total       0.87      0.87      0.87      9769\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#c) Calculate the confusion matrix and classification report (both are in sklearn.metrics). These are the same tools from HW #3.\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test,y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7956467412947869\n"
     ]
    }
   ],
   "source": [
    "#d) Calculate the roc_auc_score for this model. There are many ways to do this, but an example is to use the probabilities from step B and utilize the roc_auc_score from sklearn.\n",
    "print(roc_auc_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>marital_status_Separated</th>\n",
       "      <td>0.376066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>capital_loss</th>\n",
       "      <td>0.070819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>0.059577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>capital_gain</th>\n",
       "      <td>0.054312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hours_per_week</th>\n",
       "      <td>0.050521</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          importance\n",
       "marital_status_Separated    0.376066\n",
       "capital_loss                0.070819\n",
       "age                         0.059577\n",
       "capital_gain                0.054312\n",
       "hours_per_week              0.050521"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#e) Identify the top 5 features:\n",
    "pd.DataFrame(RF_Grid.best_estimator_.feature_importances_,index = X_train.columns,\n",
    "        columns=['importance']).sort_values('importance',ascending=False).iloc[:5,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.99      0.98     17265\n",
      "          1       0.96      0.91      0.93      5527\n",
      "\n",
      "avg / total       0.97      0.97      0.97     22792\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#f) \n",
    "y_pred_train = clf.predict(X_train)\n",
    "print(classification_report(y_train,y_pred_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is slightly overfitted as we are returnced an average accuracy of 97% for our \n",
    "training data while our test data returned an accuracy  of 87%. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise',\n",
       "       estimator=GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "              presort='auto', random_state=None, subsample=1.0, verbose=0,\n",
       "              warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=-1,\n",
       "       param_grid={'max_depth': [1, 2], 'learning_rate': [0.5, 1], 'random_state': [0], 'n_estimators': [100, 200, 300, 400]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring='roc_auc', verbose=0)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Part 4\n",
    "#a) Use GradientBoostingClassifier along with GridSearchCV\n",
    "param_grid = {'max_depth':[1,2],\n",
    "'learning_rate':[.5,1],\n",
    "'random_state':[0],\n",
    "'n_estimators':[100,200,300,400]}\n",
    "GBC = GridSearchCV(GradientBoostingClassifier(), param_grid, cv=10, n_jobs=-1, scoring='roc_auc')\n",
    "GBC.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 1 ... 0 1 1]\n",
      "[[0.99197158 0.00802842]\n",
      " [0.39465778 0.60534222]\n",
      " [0.28501753 0.71498247]\n",
      " ...\n",
      " [0.99566338 0.00433662]\n",
      " [0.46147546 0.53852454]\n",
      " [0.00232775 0.99767225]]\n"
     ]
    }
   ],
   "source": [
    "#b) Calculate predictions for the training data & build the classification report & roc_auc_score. Are there signs of overfitting? Why or why not?\n",
    "y_pred = GBC.predict(X_test)\n",
    "print(GBC.predict(X_test))\n",
    "print(GBC.predict_proba(X_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      0.90      0.92      7800\n",
      "          1       0.65      0.77      0.71      1969\n",
      "\n",
      "avg / total       0.88      0.87      0.88      9769\n",
      "\n",
      "[[7000  800]\n",
      " [ 455 1514]]\n"
     ]
    }
   ],
   "source": [
    "#c)\n",
    "print(classification_report(y_pred,y_test))\n",
    "print(confusion_matrix(y_pred,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.796622721056967\n"
     ]
    }
   ],
   "source": [
    "#d)\n",
    "print(roc_auc_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>marital_status_Separated</th>\n",
       "      <td>0.376066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>capital_loss</th>\n",
       "      <td>0.070819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>0.059577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>capital_gain</th>\n",
       "      <td>0.054312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hours_per_week</th>\n",
       "      <td>0.050521</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          importance\n",
       "marital_status_Separated    0.376066\n",
       "capital_loss                0.070819\n",
       "age                         0.059577\n",
       "capital_gain                0.054312\n",
       "hours_per_week              0.050521"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#e) Identify the top 5 features:\n",
    "pd.DataFrame(GBC.best_estimator_.feature_importances_,index = X_train.columns,\n",
    "        columns=['importance']).sort_values('importance',ascending=False).iloc[:5,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.95      0.93     17265\n",
      "          1       0.81      0.69      0.75      5527\n",
      "\n",
      "avg / total       0.88      0.89      0.88     22792\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#f)\n",
    "y_pred_train = GBC.predict(X_train)\n",
    "print(classification_report(y_train,y_pred_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model is not overfitted as it retains an accuracy of around 88% from our training model to our test model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=10, error_score='raise',\n",
       "          estimator=GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "              presort='auto', random_state=None, subsample=1.0, verbose=0,\n",
       "              warm_start=False),\n",
       "          fit_params={}, iid=True, n_iter=10, n_jobs=-1,\n",
       "          param_distributions={'max_depth': [1, 2], 'learning_rate': array([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1. , 1.1, 1.2, 1.3,\n",
       "       1.4, 1.5, 1.6]), 'random_state': [0], 'n_estimators': [100, 200, 300, 400]},\n",
       "          pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "          scoring='roc_auc', verbose=0)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Part 5\n",
    "#a) a use the following parameters:\n",
    "param_grid = {'max_depth':[1,2],\n",
    "'learning_rate':np.arange(.1,1.7,.1),\n",
    "'random_state':[0],\n",
    "'n_estimators':[100,200,300,400]}\n",
    "xg = RandomizedSearchCV(GradientBoostingClassifier(), param_grid, cv=10, n_jobs=-1, scoring='roc_auc')\n",
    "xg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 1 ... 0 1 1]\n",
      "[[0.99172061 0.00827939]\n",
      " [0.40968564 0.59031436]\n",
      " [0.35345037 0.64654963]\n",
      " ...\n",
      " [0.99494009 0.00505991]\n",
      " [0.4455486  0.5544514 ]\n",
      " [0.00342006 0.99657994]]\n"
     ]
    }
   ],
   "source": [
    "#b) Calculate predictions for the training data & build the classification report & roc_auc_score. Are there signs of overfitting? Why or why not?\n",
    "y_pred = xg.predict(X_test)\n",
    "print(xg.predict(X_test))\n",
    "print(xg.predict_proba(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      0.90      0.92      7831\n",
      "          1       0.65      0.78      0.71      1938\n",
      "\n",
      "avg / total       0.88      0.87      0.88      9769\n",
      "\n",
      "[[7019  812]\n",
      " [ 436 1502]]\n"
     ]
    }
   ],
   "source": [
    "#c)\n",
    "print(classification_report(y_pred,y_test))\n",
    "print(confusion_matrix(y_pred,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7953041208936129\n"
     ]
    }
   ],
   "source": [
    "#d)\n",
    "print(roc_auc_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>capital_gain</th>\n",
       "      <td>0.122555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>capital_loss</th>\n",
       "      <td>0.120927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>0.077467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hours_per_week</th>\n",
       "      <td>0.076557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>education_num</th>\n",
       "      <td>0.065115</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                importance\n",
       "capital_gain      0.122555\n",
       "capital_loss      0.120927\n",
       "age               0.077467\n",
       "hours_per_week    0.076557\n",
       "education_num     0.065115"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#e) Identify the top 5 features:\n",
    "pd.DataFrame(xg.best_estimator_.feature_importances_,index = X_train.columns,\n",
    "        columns=['importance']).sort_values('importance',ascending=False).iloc[:5,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.95      0.92     17265\n",
      "          1       0.80      0.67      0.73      5527\n",
      "\n",
      "avg / total       0.88      0.88      0.88     22792\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#f)\n",
    "y_pred_train = xg.predict(X_train)\n",
    "print(classification_report(y_train,y_pred_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model is not overfitted as it retains an accuracy of around 88% from our training model to our test model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) What does the alpha parameter represent in AdaBoost? Please refer to chapter 7 of the Hands-On ML book if you are struggling.\n",
    "Alpha is the weight that is applied to a classifier. The first time the model is trained, alpha will be weighted equally for all classifiers. The alpha will decrease for a given paramter as it's misclassifications increase. The equations for alpha is the number of missclassifications over the training set divided by the training size.\n",
    "alpha = .5*ln((1-Miss_err)/Tot_err)\n",
    "\n",
    "b) In AdaBoost explain how the final predicted class is determined. Be sure to reference the alpha term in your explanation.\n",
    "In Adaboost, each feature is used as a decsion tree (aka a stump due to 1 paramter) for the dependent variable. Parametrs are given weights as to how well they can classify the dependent variable. Within each parameter classification, each sample has an equal weight before the first model. The misclassified samples will then take on a higher weight comparatively towards the samples that were correctly classified since we want out parameter to be able to capture these misclassified samples. The misclassified samples will take the (original weight)*e^(-alpha*actual*predicted). \n",
    "\n",
    "\n",
    "c) In Gradient Boosting, what is the role of the max_depth parameter? Why is it important to tune on this parameter?\n",
    "The max depth indicates how deep our tree can be built out. The deeper you allow a tree to be built out, the higher possibility you can have an overfitted mode. It is important to tune this parameter so that you don't overfit the model. \n",
    "\n",
    "d) In Part (e) of Steps 2-5 you determined the top 5 predictors across each model. Do any predictors show up in the top 5 predictors for all three models? If so, comment on if this predictor makes sense given what you are attempting to predict. (Note: If you don't have any predictors showing up across all 3 predictors, explain one that shows up in 2 of them). Age, Capital Gain, and Capital loss showed up across all the models as one of the top 5 determinants for our dependent variable. It seems the older you are, the more likely you are to make more than 50K a year. If you have high capital gains and losses, it means you have a lot of money in the market which typically means that person is a large amount of disposable income that isn't needed for essential goods.\n",
    "\n",
    "e) From the models run in steps 2-5, which performs the best based on the Classification Report? Support your reasoning with evidence from your test data and be sure to share the optimal hyperparameters found from your grid search.\n",
    "\n",
    "f) For your best performing model, plot out a ROC curve using your test data. Feel free to use sklearn, matplotlib or any other method in python. Describe what the x-axis & y-axis of the ROC curve tell us about a classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e) From the models run in steps 2-5, which performs the best based on the Classification Report? Support your reasoning with evidence from your test data and be sure to share the optimal hyperparameters found from your grid search.\n",
    "The GradientBoostingClassifier along with GridSearchCV returned the high roc_auc_score with a value of .797.\n",
    "The hyperparameters are in the cell below. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'friedman_mse',\n",
       " 'init': None,\n",
       " 'learning_rate': 0.5,\n",
       " 'loss': 'deviance',\n",
       " 'max_depth': 2,\n",
       " 'max_features': None,\n",
       " 'max_leaf_nodes': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_impurity_split': None,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'n_estimators': 400,\n",
       " 'presort': 'auto',\n",
       " 'random_state': 0,\n",
       " 'subsample': 1.0,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GBC.best_estimator_.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ggplot\n",
      "  Using cached https://files.pythonhosted.org/packages/48/04/5c88cc51c6713583f2dc78a5296adb9741505348c323d5875bc976143db2/ggplot-0.11.5-py2.py3-none-any.whl\n",
      "Requirement already satisfied: pandas in c:\\users\\u353822\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from ggplot) (0.22.0)\n",
      "Requirement already satisfied: patsy>=0.4 in c:\\users\\u353822\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from ggplot) (0.5.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\u353822\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from ggplot) (1.14.2)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\u353822\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from ggplot) (2.2.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\u353822\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from ggplot) (1.0.0)\n",
      "Requirement already satisfied: cycler in c:\\users\\u353822\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from ggplot) (0.10.0)\n",
      "Requirement already satisfied: six in c:\\users\\u353822\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from ggplot) (1.11.0)\n",
      "Collecting brewer2mpl (from ggplot)\n",
      "  Using cached https://files.pythonhosted.org/packages/84/57/00c45a199719e617db0875181134fcb3aeef701deae346547ac722eaaf5e/brewer2mpl-1.4.1-py2.py3-none-any.whl\n",
      "Requirement already satisfied: statsmodels in c:\\users\\u353822\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from ggplot) (0.8.0)\n",
      "Requirement already satisfied: python-dateutil>=2 in c:\\users\\u353822\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from pandas->ggplot) (2.6.1)\n",
      "Requirement already satisfied: pytz>=2011k in c:\\users\\u353822\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from pandas->ggplot) (2017.3)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in c:\\users\\u353822\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from matplotlib->ggplot) (2.2.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\u353822\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from matplotlib->ggplot) (1.0.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\u353822\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from kiwisolver>=1.0.1->matplotlib->ggplot) (38.4.0)\n",
      "Installing collected packages: brewer2mpl, ggplot\n",
      "Successfully installed brewer2mpl-1.4.1 ggplot-0.11.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using pip version 18.1, however version 19.0.2 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n",
      "C:\\Users\\u353822\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ggplot\\utils.py:81: FutureWarning: pandas.tslib is deprecated and will be removed in a future version.\n",
      "You can access Timestamp as pandas.Timestamp\n",
      "  pd.tslib.Timestamp,\n",
      "C:\\Users\\u353822\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ggplot\\stats\\smoothers.py:4: FutureWarning: The pandas.lib module is deprecated and will be removed in a future version. These are private functions and can be accessed from pandas._libs.lib instead\n",
      "  from pandas.lib import Timestamp\n",
      "C:\\Users\\u353822\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\statsmodels\\compat\\pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n"
     ]
    }
   ],
   "source": [
    "!pip install ggplot\n",
    "from ggplot import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAuEAAAHvCAYAAAD6ogF/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzs3XlcVGX/PvBrmIEBBAQRUNTIJQlDDddSk0hBFNw1MwszTTLNLZfKyiVN0+fx97iU9mSLe5iaS26QmmuZuYMrqLgggqyyzcKc3x898o1ABQbmPpy53q9XL3M4OBcfD3Jxc885KkmSJBARERERkcXYiA5ARERERGRtWMKJiIiIiCyMJZyIiIiIyMJYwomIiIiILIwlnIiIiIjIwljCiYiIiIgsTCM6QHWQlJRkseeytbWFh4cHUlNTYTAYLPa85aHVaqHT6UTHKBXnV3GcnXk4P/NwfuaR+/w4O/NwfsV5e3tb5HmqGlfCqdxsbHjamIPzqzjOzjycn3k4v4rj7MzD+SkT/1aJiIiIiCyMJZyIiIiIyMJYwomIiIiILIwlnIiIiIjIwljCiYiIiIgsjCWciIiIiMjCWMKJiIiIiCyMJZyIiIiIyMJYwomIiIiILIwlnIiIiIjIwljCiYiIiIgsjCWciIiIiMjCWMKJiIiIiCyMJZyIiIiIyMI0ogNUhmPHjuH06dNISUmBv78/+vbtW+pxp0+fxrFjx5CWlgatVovmzZujS5cuUKvVFk5MRERERNZMESXc2dkZnTt3RkJCAgwGw0OPMxgMCA0NRb169ZCXl4f169fj6NGjeOGFFyyYloiIiIisnSJKeLNmzQAASUlJjyzhbdu2Lfp/FxcXNG/eHNevXy92THZ2NnJycoo9ptfrUaNGjcoL/AgajabYr3KkVqtha2srOkapOL+K4+zMw/mZh/Mzj9znx9mZh/NTJqueWGJiIjw8PIo9duLECRw4cKDYY4GBgQgKCrJkNLi5uVn0+ZSG86s4zs48nJ95OD/zcH4Vx9lVTFJSElQqFedXAVZbwk+dOoWkpCT06tWr2OOtW7eGr69vscf0ej1SU1Mtkkuj0cDNzQ0ZGRkwGo0Wec7y0mq10Ol0omOUivOrOM7OPJyfeTg/88h9fpydeeQ4v40bNyI+Ph4fffQRXF1dLTq/fy6gVldWWcIvXLiAX375BRERESW2mbi4uMDFxaXYY4/b5lIVjEajxZ+zrDQajWyzPcD5VRxnZx7Ozzycn3nkOj/Ozjxyml9WVhY+/PBDxMXFYenSpUXFW87zkyurK+FXrlzB9u3b8eqrr8LLy0t0HCIiIqJq45tvvoGrqyt27doFBwcH0XGqNUWU8MLCQphMJkiSBEmSYDAYYGNjU+LSg1evXsXmzZsxaNAg1K9fX1BaIiIioupDr9dj4cKFCAkJwYQJE6BSqURHUgRFlPCDBw8WezHl2bNnERgYiICAAHzxxRcYPXo0XF1dcfDgQRQUFGDt2rVFx/r4+OC1114TEZuIiIhI1uLj4/Huu+/Cw8MDw4cPZwGvRIoo4UFBQQ+9esm0adOK/v+NN96wUCIiIiKi6s1kMmHcuHF45ZVXEBERwQJeyXjbeiIiIiIqkp6ejk8//RRGoxFbt27F0KFDWcCrAEs4EREREQEAfv31VwQHBxeVbt6Ep+pwskRERESEy5cvY/LkyVi8eDE6duwoOo7isYQTERERWbELFy4gLi4OAwYMwMGDB3npQQvhdhQiIiIiK2QymfDf//4XL7/8ctFjLOCWw5VwIiIiIiv0xRdfIDo6Gtu3b8eTTz4pOo7V4Uo4ERERkRXZvXs3rl+/jmHDhuGnn35iAReEJZyIiIjICuTm5mLy5MmYNWsWcnJy4OTkxKufCMQSTkRERKRwkiRh0KBBMBqNiI6Ohr+/v+hIVo/f/hAREREpVGFhIbZt24Y+ffpgxYoVqFOnjuhI9D8s4UREREQKdPPmTYwdOxYajQZdu3ZlAZcZbkchIiIiUpirV68iLCwMISEhiIqKgrOzs+hI9A9cCSciIiJSiKysLFy+fBlt2rTBli1b0KhRI9GR6CG4Ek5ERESkAL///jtCQkLwyy+/QKVSsYDLHFfCiYiIiKq59evXY8GCBZg/fz66du0qOg6VAUs4ERERUTWVkJAANzc3dO7cGV27doWHh4foSFRG3I5CREREVM1IkoS1a9eid+/eOH36NOrVq8cCXs1wJZyIiIioGpEkCaNHj0Z8fDw2b96Mpk2bio5EFcASTkRERFRNXL58GU2bNkVERAQCAgKg1WpFR6IK4nYUIiIiIpkrKCjAJ598giFDhiAjIwPPPfccC3g1xxJOREREJGNJSUkICwtDcnIyoqOj4ebmJjoSVQJuRyEiIiKSIZPJhDt37sDHxweTJk1CaGgoVCqV6FhUSVSSJEmiQ8hdWloabGws80MDlUoFOzs76PV6yPWvxsbGBiaTSXSMUnF+FcfZmYfzMw/nZx65z4+zK7/k5GSMHj0aLi4uWLlyJef3N0r5SQBXwstAp9NZ7LlsbW3h6uqK3NxcGAwGiz1veTg4OCA/P190jFJxfhXH2ZmH8zMP52ceuc+PsyufgwcPYuzYsXj99dcxbtw4mEwmzu9vWMKJiIiIqNLk5eVBpVKhVq1a+Prrr9G2bVvRkagK8YWZRERERIKdPn0aISEh2LlzJ/z9/VnArQBLOBEREZFAS5cuRUREBKZMmYL+/fuLjkMWwu0oRERERALk5eXB0dERbm5u2LVrF+rVqyc6ElkQV8KJiIiILGzLli3o1KkT7t27hyFDhrCAWyGuhBMRERFZyP379/Hhhx/izJkzWLlyJWrXri06EgnClXAiIiIiC9Dr9QCA+vXrY8+ePWjevLngRCQSSzgRERFRFTIYDPj888/x5ptvwtnZGVOnToWDg4PoWCQYSzgRERFRFbl69Sr69OmDc+fOYeHChaLjkIxwTzgRERFRJZMkCZIk4fr16xgwYADeeOMNqFQq0bFIRljCiYiIiCpReno6pkyZgqCgIAwZMkR0HJIpbkchIiIiqiQHDx5EcHAwfHx8MGDAANFxSMa4Ek5ERERkJkmSoFKpsHfvXvy///f/0LlzZ9GRSOa4Ek5ERERkhosXL6JPnz5ITk7GzJkzWcCpTFjCiYiIiCrAZDJhxYoVGDhwIF599VV4eXmJjkTVCLejEBEREVVAeno6Dhw4gG3btqFhw4ai41A1w5VwIiIionLYs2cPxo8fj9q1a2P16tUs4FQhXAknIiIiKoO8vDzMmDEDhw4dwuLFi0XHoWqOJZyIiIioDHbt2gWdTofo6Gg4OzuLjkPVHEs4ERER0UMUFhbiyy+/xBNPPIF+/fqhf//+oiORQnBPOBEREVEpbt++jZdffhkHDhxAmzZteNt5qlRcCSciIiIqxYwZM9ClSxdERkZCrVaLjkMKo5gSfuzYMZw+fRopKSnw9/dH3759H3rsb7/9hsOHD8NoNMLPzw/h4eHQaBQzCiIiIqqg7OxszJ8/HxMmTMBXX30FGxtuGqCqoZgzy9nZGZ07d0ZAQMAjj4uPj8fhw4cxdOhQjB8/HhkZGdi/f7+FUhIREZFc/fHHHwgJCYHRaISDgwMLOFUpxZxdzZo1g5+fHxwcHB553OnTpxEQEABPT084ODggMDAQp0+ftlBKIiIikqP09HSMGzcOs2bNwrx58+Do6Cg6Eimc1e3BSE1NxdNPP130ey8vL+Tm5iIvLw+Ojo7Izs5GTk5OsffR6/WoUaOGRfI92BYj5+0xarUatra2omOUivOrOM7OPJyfearj/PR6PUwmE4xGY9Fjd+/ehcFgEJItJSUFWVlZKCwstPjzP4wkSUhJSQEAIXP5p4yMDGRnZxd7gWVqairOnz+PtWvX4ujRo7CzsxOYsHT83FUmq5uYXq+HVqst+r29vT0AQKfTwdHRESdOnMCBAweKvU9gYCCCgoIsmtPNzc2iz6c0nF/FcXbm4fweTpIkZGRkPPRtN27cQFJSEnJycnD37l04OTlBkiQkJCRArVYjNzcXN2/efORPPBMSEgAAKpUKJ06cgJeXV9Hb7t+/jytXrqBWrVpmfxz5+fkoKCgAgKJFGoPBABcXF3h6epr15yuNi4uLbD4v9Ho91Go1GjduDEmScPHiRfz+++/o378/XF1dZZOzOuLsys/qSridnR10Ol3R7x/8/4Ni3rp1a/j6+hZ7H71ej9TUVIvk02g0cHNzQ0ZGRrHVFTnRarXFZignnF/FcXbmUcL88vPzkZ2djVu3bgH4q2zev38fN27cQM2aNXH06FEAKFpFNBqN2Lx5MwwGAzw9PVFQUICCggJIklTqn5+bmwsAcHV1LfXtmZmZ8Pb2RuPGjREfH49nnnkGGo0GeXl5qF+/PmrUqAGdTod69eo99GOoWbMmXF1dUbNmTfTu3RtPPPFEsbc7OjrC3d39oe//KH+fn729Pezt7WEymWSxAij380+On7ubNm3CwYMH8csvv6Bjx46ynR0gz/k9IOLc8/DwsMjzVDXx/3JYmIeHB+7evQt/f38AQHJyMmrUqFG098vFxQUuLi7F3icpKcniP0YzGo2y+NFdaTQajWyzPcD5VRxnZx45zy82NhZ//vknjh8/DhsbG6jVaiQnJyMvLw+///570XEeHh6oX78+gL8+HkmS0LBhQ+Tm5qJ9+/ZwcnIqOnbRokVo1KgRHB0dYW9vD61W+8gXszk4OJR6qTdbW1t4eHggNTVVtvNzcHBAfn5+0e8fbPuQU165nn9y+tw9ePAgtFotunfvjm7duhWdz3KdHSCv+T2MnOcnV4op4YWFhTCZTJAkCZIkwWAwFH2R+buWLVtiy5YtaN68OZydnXHw4EE8++yzglITEZlPkiQcP34cOp2uaA9ubGwsdDod0tPTkZaWht9++w0A0LBhQ/j6+uKpp55CgwYNAPxVgMeOHYuOHTtCrVbzhiSkSAUFBZg3bx62b9+OJUuWyHaPNVkPxZTwgwcPFtvLffbsWQQGBiIgIABffPEFRo8eDVdXVzz11FPo2LEjVq5cCYPBgGbNmll8vzcRUXmYTKai/ccnT55EfHw8VCoV7ty5gx9//BHJyckAgI4dOwIAPD09cfXqVTRr1gwBAQFo2rQpJk6ciBdeeEFWL9ojsqRx48bBZDIhJibG7NcFEFUGxZTwoKCgh5bpadOmFft9hw4d0KFDB0vEIiKqkLy8POzevRunTp3Ct99+C+D/tkO0aNECLVu2hMlkQmhoKPr27YsmTZo8dK/1A3Z2dsW2UxApnSRJ2LBhA3r16oW5c+fCzc2NP+kh2VBMCScikqP8/Hzcv38fGRkZUKvVyM7Oxv3795GTk4PCwkL8+eef+Pnnn+Hm5oaLFy8CAJycnIouldqjRw+8/vrrmDlzZrErOxHRo6WkpGDixInIzMxE586dUbduXdGRiIphCSciMtOD6yAnJibizp07SEhIQEZGBvbu3YsjR44UHdeoUSO4uLjAyckJzs7OUKvVSEhIwPTp09G0aVMAQL169aBSqaDRaB578zEiKl12dja6d++OQYMGYcKECdz/TbLEEk5EVA7nz5/HvXv3sGnTJmzcuBHAX9tE3NzckJaWhkaNGsFgMODpp59GkyZNEBERge7du5d6RRAiqlx5eXk4cuQIgoODsW3btkdezpJINJZwIqKHSE9Px2+//YaEhATcvHkT69atAwAEBATAaDSiV69emD9/PpycnGBnZyf7S+wRKdnZs2cxevRotGnTBl27dmUBJ9ljCSciq2Y0GrFhwwZcvHgRNjY2UKlUuHTpUrGrLfn6+qJWrVr44IMPMHjw4Arf7IWIqsa+ffswfvx4fPrpp+jdu7foOERlwhJORFYjPz8ft2/fxrlz5/DHH39g27ZtyMzMBAC89NJLePrpp+Hu7o7GjRtj+vTpRXdpJCJ5un37NgoKCtCuXTvs2rWLq99UrbCEE5EiFBYW4u7du9DpdEhLS0NeXh7S0tIgSRKio6NRWFiInTt3Avjr1uUdOnTAJ598gg4dOsDb25t7tomqma1bt+Ljjz/GtGnTMGjQoGJ3ciWqDljCiahaS05OxtSpU7F3715IkgQfHx9kZWXByckJzZo1Q40aNZCVlYVOnTph4sSJ8PPzEx2ZiMw0c+ZM/PLLL1i9ejVatmwpOg5RhbCEE1G1k5mZiaVLl+Knn35CcnIy6tSpgy+//BI9e/bkjTiIFCw2NhZ+fn4YMGAAJk+eDEdHR9GRiCqMJZyIZEuSJFy+fBmnT5/GpUuXoFar8eWXXwIAatasid69e+Pdd9+Ft7e34KREVJUMBgP+85//YO3atdi4cSOeeeYZ0ZGIzMYSTkSyc+bMGYwZMwZXr14teqxPnz6oU6cOJkyYgP79+6Nhw4YCExKRpeTm5mLQoEGoWbMm9uzZAy8vL9GRiCoFSzgRycakSZOwfv16AEC3bt2wePFiNGrUCDVr1gTw101x8vPzRUYkIguRJAnXrl1Do0aNMHHiRLz44ouwsbERHYuo0rCEE5FQWVlZWL16NTZv3oxLly4hMjISo0aNgoeHh+hoRCRIeno6pk6dirt372LLli146aWXREciqnQs4UQkRF5eHubNm4dvvvkGANC+fXts3rwZ7du3F5yMiEQ6ffo0RowYgfDwcCxZsoSr36RYLOFEZFFxcXF48803cevWLQDAhx9+iMjISGg0/OeIyJrpdDrk5uaibt26WLhwITp37iw6ElGV4lc9IrKIn376CdOmTUNWVhYcHBxw7Ngx1K9fX3QsIpKBS5cuYcyYMejZsyfGjh3LF1+SVWAJJ6IqYzKZsGnTJmzatAmHDh1CixYtsHHjRt4KnoiKrF27FvPmzcOHH36IV155RXQcIothCSeiSmMymbB9+3ZER0cjPj4esbGxAICOHTti165daNGiheCERCQXWVlZcHFxgYeHB7Zu3YpGjRqJjkRkUSzhRGQ2k8mEP/74A/379wcAjBw5EoMGDULjxo3h7e3Nu1gSUTHR0dGYOnUq1qxZg5CQENFxiIRgCSeiCtPr9ejXrx9OnToFAPjoo4/w9ttvs3QTUal0Oh2mT5+OX3/9FV999RXvfElWjSWciMpt+/btiIqKwv79+wEAa9aswYsvvsjyTUQPlZ+fDzs7O3h7eyM6OhouLi6iIxEJxYtvElGZ3bhxA02bNsXbb7+NFi1aYOvWrbh16xaCgoJYwImoVIWFhVi0aBF69uwJABg7diwLOBEAlSRJkugQcpeWlmaxmwWoVCrY2dlBr9dDrn81NjY2MJlMomOUivOruEfNLjMzE3PnzsXXX38NAEhISICbm5vFM8p1dgDPPXNxfuaR6/xu3bqFUaNGQZIkLFu2DA0aNBAdqQS5zu7veO4VJ+LrT1XgdpQy0Ol0FnsuW1tbuLq6Ijc3FwaDwWLPWx4ODg7Iz88XHaNUnF/FlTY7o9GIYcOG4fjx46hXrx6io6OL9nCK+BjkOjuA5565OD/zyHF+RqMRaWlp6Ny5MyZOnAi9Xi/L+clxdv/Ec684lnAiUrSUlBQEBwfj3r17WLRoEfr3788tJ0T0WPfv38e0adNQt25dfPDBB2jatCnUarXoWESywz3hRFSMJEmYMWMGAgICUK9ePRw9ehQDBgxgASeixzp+/DhCQkJgb2+PcePGiY5DJGtcCSeiInv27EFoaCgAYPz48Xjvvfcs9noIIqq+JEmCSqXCyZMnMWPGDHTr1k10JCLZ41dXIgIAXL9+HaGhoRg8eDBu3LiByZMns4AT0WNdv34dffr0wZkzZxAZGckCTlRG/ApLZOW+//579O3bF+3atcOLL76If//739y/SUSPJUkSoqKi0LNnT/Tq1QvNmzcXHYmoWmEJJ7JiM2fOxLRp09C4cWP861//wr59+6DRcJcaET2eXq/Hvn37sGHDBgwfPpw/OSMqJ361JbJS77zzDrZu3YqffvoJ7dq1g62tLV98SUSPdejQIXzxxRdYs2YNvvrqK9FxiKotlnAiK5Oeno63334bR44cwebNm9GuXTvRkYioGtDpdPj888+xdetWLFy4kD81IzITP4OIrMipU6cQHh6OF154AfHx8XBwcBAdiYiqiXPnzuHmzZuIiYlBrVq1RMchqvZYwomshE6nQ3h4OADghx9+EJyGiKoDSZKwcuVK3L9/H++++y7atGkjOhKRYrCEE1kBo9GIRo0aAQA2b94sOA0RVQepqamYOHEi0tLSsGTJEtFxiBSHL2UmUrhr165h4MCBAIDDhw+jffv2ghMRUXWwbNky+Pv7Y+vWrWjcuLHoOESKwxJOpGCbN29Gp06d0LJlS1y7dg0NGzYUHYmIZCw/Px8ff/wxLly4gI8//hhTp06Fra2t6FhEisQSTqRQUVFRePfddxEYGIgZM2bAzs5OdCQikrHY2FiEhoYiIyMD3t7evGQpURXjnnAihYmOjsa8efNw6dIlfPzxx4iMjBQdiYhkzmAwYMKECRg3bhz69esnOg6RVWAJJ1KQDh06IDExEX379sWaNWvg7e0tOhIRydjt27exYsUKfPTRR9i9ezfUarXoSERWg9tRiBTixRdfRGJiIr755hssXbqUBZyIHmn79u3o3r07XF1dAYAFnMjCuBJOpADLly/HlStXsHXrVl7Hl4ge68SJE/j888+xatUqPPvss6LjEFkllnCiaq6wsBCffvopOnTowAJORI/0559/4tatW+jTpw9++eUX2Nvbi45EZLW4HYWomvv111/h5+eHH3/8UXQUIpIpo9GIf//73xgxYgQcHBwAgAWcSDCuhBNVY1lZWYiIiMDw4cNFRyEiGZs3bx7Onz+P3bt3o06dOqLjEBFYwomqrZ9//hmRkZGwtbXFJ598IjoOEcmMJEnYuHEjOnXqhPHjx8PR0RE2NvwBOJFcsIQTVUPPPPMMMjMzMWrUKHz00Uei4xCRzGRkZGDq1KlISEhAQEAA6tatKzoSEf2DYkp4Xl4etm3bhoSEBDg6OqJLly5o0aJFieOMRiN27dqFixcvorCwEE888QTCw8Ph4uIiIDVR+R0+fBiZmZlYsWIFunfvLjoOEclMYWEh+vXrhxdeeAGLFy/m3m8imVJMCd+5cyfUajUmTZqE5ORkrFu3DnXq1IGnp2ex437//XfcunULo0aNglarxfbt27Fz50688sorgpITlV1OTg5mz56NWrVqsYATUTE6nQ4bNmxAnz59sGHDBnh4eIiORESPoIgSrtfrcf78ebzzzjvQarXw8fGBr68vzpw5g+Dg4GLHZmZmonHjxnBycgIA+Pv7Y8+ePUVvz87ORk5OTok/v0aNGlX/gQDQaDTFfpUjtVoNW1tb0TFKpdT5vfvuu4iKigIAdO/eHevXr6/0vwOlzs5SOD/zcH7mSUhIwKhRo+Dt7Y1evXrJ7mZdcp4dzz3zVIf5yZUiJpaWlgYbGxvUrl276DEvLy8kJiaWODYgIAC7d+9GdnY27O3tcfbsWTRp0qTo7SdOnMCBAweKvU9gYCCCgoKq7gMohZubm0WfT2mUMj9JkooKeLt27bB582bUq1evSp9TKbMThfMzD+dXfqdPn0bPnj3x2WefYcSIEVCpVKIjVUs898zD+ZWfIkq4Xq+HVqst9pi9vT10Ol2JY93d3VGzZk0sXLgQKpUKXl5e6NGjR9HbW7duDV9f3xJ/fmpqatWE/weNRgM3NzdkZGTAaDRa5DnLS6vVljpbOVDS/FJSUuDv7w+VSoVvvvkGPXv2BIAqOxeVNDsROD/zcH7ll5qaisTERLRq1QoxMTF49tlnZTs/uc3u73jumUfE/JSy1UoRJdzOzq7EyanT6UoUcwDYsWMHjEYjpkyZAjs7Oxw5cgRr167FW2+9BQBwcXEp8SLNpKQkGAyGqvsASmE0Gi3+nGWl0Whkm+0BJcwvMjISTk5O+P333+Hm5maxj0cJsxOJ8zMP51c2v/zyCyZPnoy33noLLVu2LPoJmVznJ6fZPYxcZwdwfkqliBLu7u4Ok8mEtLQ0uLu7AwCSk5NL/U4pOTkZXbp0gaOjIwCgXbt22L9/P3Jzcy2275voUfLy8vCvf/0LR44cwbFjx/gjPiIqZvny5fjuu++wbNkyPPfcc6LjEFEFKeKq/XZ2dvDz88P+/fuh1+tx48YNXLp0CS1btixxbL169XDmzBkUFBSgsLAQx48fh7OzMws4ycZTTz2Fbdu2YenSpahfv77oOEQkE3Fxcbh//z7CwsIQHR3NAk5UzSmihANAWFgYDAYDFixYgI0bNyIsLAyenp5ITEzEnDlzio4LCQmBRqPB4sWLMX/+fFy5cgWDBg0SmJzo//z6668AgGPHjqFv375iwxCRLJhMJixfvhyDBw/GhQsX0KBBA9SsWVN0LCIykyK2owCAo6MjBg8eXOJxHx8fTJs2rdhx/fv3t2Q0ojLR6XQYMmQI5s2bB7VaLToOEcmAyWTCa6+9hvz8fOzYsQMNGjQQHYmIKoliSjhRdTdq1CgA4E9miAgAcP78eTRr1gzjx49H69at+c05kcIoZjsKUXV15coVDB06FAcOHMDp06dhZ2cnOhIRCZSTk4Px48cjMjISeXl5aNeuHQs4kQKxhBMJdOHCBYSGhuLJJ5/En3/+qZhrnxJRxVy9ehUhISGwtbXF7t27i67kRUTKw+0oRIIYjUZ07doVL730EmbOnCk6DhEJZDQacffuXdStWxezZ8/GSy+9JDoSEVUxroQTCTJu3DgAwKpVqwQnISKREhMT0a9fPyxatAgODg4s4ERWgiWcSIDMzExs2bIF48aNg0qlEh2HiATZsWMHwsPDER4ejnnz5omOQ0QWxO0oRBb222+/ISwsDH5+fpgyZYroOEQkQGZmJhwdHVG3bl1ERUWhWbNmoiMRkYVxJZzIwiZPngw/Pz/s2LFDdBQiEuDIkSMIDg7GgQMH0KpVKxZwIivFlXAiC3r//fdx/vx5HD9+HFqtVnQcIrIgSZLw2WefYfPmzfjXv/6FoKAg0ZGISCCWcCIL2bp1K1avXo1Lly7ByclJdBwisqCcnBw4OTmhQYMGiI6Ohru7u+hIRCQYt6MQWcgnn3yCIUOG8FrgRFZEkiR8//2cpXiPAAAgAElEQVT3CAwMxP379xEREcECTkQAuBJOZBErVqzAvXv3MGvWLNFRiMhC0tPTMX78eKSmpiIqKgrOzs6iIxGRjLCEE1WxDRs24PPPP8fgwYNhb28vOg4RWYBOpwMAtGrVCu+88w7s7OwEJyIiuWEJJ6oiOTk5aNWqFQoLC7F9+3ZeAYHICuTn52P27NlIS0vD8uXLMX78eNGRiEimuCecqAqcPXsWvr6+yM3NRVxcHAs4kRWIjY1Fjx49kJGRwRvvENFjcSWcqJIlJyeje/fuAICbN2/Cxobf6xIpmclkgkqlwo0bNzBmzBj069ePd8IlosdiCSeqZJ07d0aNGjVw6dIlfiEmUrg7d+5g/PjxGDJkCHr16iU6DhFVI1yiI6pEJ06cgMFgwMmTJ1nAiRRux44dCA0NxXPPPYcePXqIjkNE1QxXwokqiclkwrBhwzBlyhTejIdIwSRJAvDX7ee/++47tGrVSnAiIqqOuBJOVElOnDiBtLQ0DB8+XHQUIqoiJ0+eRHh4OLKysvDZZ5+xgBNRhbGEE1WS5cuXo3fv3rweMJECGY1GzJ8/H8OGDcPo0aPh6uoqOhIRVXPcjkJUCW7evIljx47h6NGjoqMQURW4e/cuzp07h927d6Nu3bqi4xCRAqikB5vb6KHS0tIsdpk5lUoFOzs76PV6yPWvxsbGBiaTSXSMUomY39WrVzFmzBh06NABH3300WOPl+v8eO6Zh/MzjxznJ0kSoqKi8Mcff2DhwoWcnxk4O/NwfsW5ublZ5HmqGlfCy+DB7YctwdbWFq6ursjNzYXBYLDY85aHg4MD8vPzRccolYj5BQcHo2HDhhg7dmyZ5iLX+fHcMw/nZx65zS8zMxMffPABLl26hCVLliA/P5/zMwNnZx7OrziWcCJCTk4OMjIyEBMTA1tbW9FxiKiSbNu2DbVr18bChQvh4OAgOg4RKRBLOJEZli9fDgDcI0qkAHq9HgsWLEC7du0QEREhOg4RKRyvjkJUQfn5+Vi1ahXWrl0rOgoRmSk+Ph69evXClStXeNlBIrIIroQTVVBUVBTs7e3x4osvio5CRGaaMWMGhgwZgtdee413uyUii+BKOFEFnD17FtOmTcOYMWNERyGiCrp37x6mTJmC7OxsrF69Gq+//joLOBFZDEs4UQVMmDABY8eO5b5Rompq3759CAkJgaurK+zt7Vm+icjiuB2FqJyOHDmCixcvIiYmRnQUIqqA27dv4+OPP8bSpUvRoUMH0XGIyEqxhBOV04ULFwDAYjdwIqLKERcXh0OHDuHtt9/GgQMHoNHwSyARicMWQVQOkiRh8eLFGDZsmOgoRFRGJpMJX331FV555RXUrl0bAFjAiUg4/itEVA4xMTFIS0vD1KlTRUchojJatWoVdu7ciR07duCJJ54QHYeICABLOFG5HD9+HADg7OwsOAkRPc7OnTtRt25dDB48GK+99hpXv4lIVrgdhaiM9Ho9vv32W3z00UeioxDRI+Tm5uK9997DnDlzYGNjA61WywJORLLDf5WIyuj9999HQUEB+vbtKzoKET3C8OHDUa9ePezZswdOTk6i4xARlYolnKgMbt++jaioKPTu3Rt16tQRHYeI/sFoNGLdunV45ZVXsHz5cri6uoqORET0SNyOQlQGX375JRo0aIBFixaJjkJE/3Djxg0MGDAAO3bsQE5ODgs4EVULLOFEj/Hjjz/i+++/x5YtW2Brays6DhH9TUpKCsLDwxEaGor169ejVq1aoiMREZUJt6MQPYIkSRg/fjwCAwO5DYVIRrKysnD8+HF07doVe/bsQd26dUVHIiIqF66EEz3Cg7tjfvXVV4KTENEDv/32G4KDg3HkyBEAYAEnomqJK+FEj3Du3Dm88MILvC44kUxs3boVM2fOxIIFC9ClSxfRcYiIKowlnOghTCYTFi9ejClTpoiOQmT14uPjYWdnh86dOyM6Orro9vNERNUVt6MQPcSUKVNw/fp1hIaGio5CZLUkScLq1avRt29fxMXFwc3NjQWciBSBK+FED6FSqdC+fXtotVrRUYis1sSJE3H+/Hls3rwZTz31lOg4RESVRjElPC8vD9u2bUNCQgIcHR3RpUsXtGjRotRjk5KSsHv3bty5cwd2dnZ44YUX8Nxzz1k4McmZyWTCunXrsH79etFRiKzSyZMnERAQgOHDh6Np06aws7MTHYmIqFIppoTv3LkTarUakyZNQnJyMtatW4c6derA09Oz2HG5ublYs2YNQkND0axZMxQWFiI7O1tQapKr69evAwA6deokNgiRlcnPz8esWbOwa9cubNmyBf7+/qIjERFVCUXsCdfr9Th//jyCgoKg1Wrh4+MDX19fnDlzpsSxv/32G5o0aYIWLVpAo9FAq9XCw8NDQGqSs/T0dPj7+8PGRhGfIkTVwr1799CtWzekpKQgJiYG9erVEx2JiKjKKGIlPC0tDTY2NsVerOPl5YXExMQSx966dQteXl5YsWIF0tPTUb9+ffTo0aPoNsfZ2dnIyckp9j56vR41atSo2g/ifzQaTbFf5UitVsv2zpGVNb+VK1fCxcWlSj5Ouc6P5555OL+KM5lMuHr1Ktq1a4c5c+agU6dOUKlUomOVINf5AfI//zg783B+yqSIien1+hIvnrO3t4dOpytxbHZ2Nu7cuYOIiAh4enoiJiYGmzZtwvDhwwEAJ06cwIEDB4q9T2BgIIKCgqruAyiFm5ubRZ9PacydX1xcHGbOnGmVPyXhuWcezq98kpKSMHToUNja2mLHjh3o16+f6EjVGs+/iuPszMP5lZ8iSridnV2Jwq3T6Uq9qoWtrS38/PyKfsz54osvYv78+SgoKIC9vT1at24NX1/fYu+j1+uRmppadR/A32g0Gri5uSEjIwNGo9Eiz1leWq221G9w5KAy5nft2jVcunQJ/v7+VfL3Ltf58dwzD+dXfocPH0ZkZCTeeOMNTJ48GSqVivOrILmff5ydeTi/4pSyQKaIEu7u7g6TyYS0tDS4u7sDAJKTk0v9S/Ly8ir1z5AkCQDg4uICFxeXYm9LSkqCwWCo5NSPZjQaLf6cZaXRaGSb7QFz5nfu3DkEBwfDzc2tSj5Ouc+P5555OL/Hy83NhcFggLe3N1asWIE2bdoUvY3zM49c58fZmYfzUyZFvOrMzs4Ofn5+2L9/P/R6PW7cuIFLly6hZcuWJY599tlncfHiRdy5cweFhYU4ePAgnnjiCTg4OAhITnKUmJgIHx8f0TGIFOnUqVPo1q0btmzZggYNGhQr4ERE1kQRJRwAwsLCYDAYsGDBAmzcuBFhYWHw9PREYmIi5syZU3Rco0aN0KVLF6xbtw4LFixAeno6+vfvLzA5yYkkSdi0aRMaNGggOgqR4ixbtgxvvPEG3n//fbzxxhui4xARCaWI7SgA4OjoiMGDB5d43MfHB9OmTSv2WNu2bdG2bVtLRaNq5NSpU8jKykJERIToKESKkZGRATc3Nzz55JPYtWsXvL29RUciIhJOMSvhRJUhLi4OzZo14935iCrJ5s2bERgYiMTERHTv3p0FnIjofxSzEk5UGaKiotCxY0fRMYiqvdzcXEyZMgVxcXFYt24dX2dBRPQPXAkn+ptz586Vuq2JiMouPz8fdnZ2aNasGXbt2sVbzxMRlYIlnOh/7t69C6PRyBU7ogrS6/WYO3cuXn75ZWg0GowePZpXniIiegiWcCL8ddvsVq1awcnJSZa3yyaSu4SEBPTu3RsXLlzAd999x88jIqLH4J5wIgDLly8HABw7dkxwEqLqRZIkGI1G5OTkYNCgQRg6dCgLOBFRGbCEEwFYs2YNnn/+ebi6uoqOQlRtpKWlYfLkyWjVqhXGjBlT6g3SiIiodNyOQlavsLAQiYmJmDt3rugoRNXGr7/+ipCQEDRu3BgjR44UHYeIqNrhSjhZvbS0NADgCzKJysBkMsHGxgaxsbFYvHgxL+lJRFRBXAknq7dmzRoA4A16iB7j/PnzCA0NRXx8PMaMGcMCTkRkBpZwsmoFBQX45ptvuBWF6BFMJhP++9//YtCgQRgxYgQaN24sOhIRUbXH7Shk1a5evQpPT09ERESIjkIkW/n5+Th16hS2b9+OJ598UnQcIiJF4Eo4WbXvv/8ely9fFh2DSJZ2796N1157DY6Ojli2bBkLOBFRJeJKOFm1e/fu8UfrRP+Qm5uLGTNm4MiRI1i8eDGv+01EVAVYwslqpaenY8+ePdizZ4/oKESycuLECRiNRkRHR8PJyUl0HCIiRSpTCS8sLMTKlSsxZMgQaLXaqs5EZBHffvstAMDf319wEiLxCgsLsXTpUtSoUQMjRoxA586dRUciIlK0Mu0JV6vVmDhxIgs4KcrRo0cxcOBA0TGIhLt16xYGDhyIQ4cOoXv37qLjEBFZhTK/MLNnz57Yvn17VWYhspj8/HzExsZi6tSpoqMQCbd06VIEBwdjw4YNqFevnug4RERWocx7wgsKCjBgwAA8//zzaNCgQbEX6qxatapKwhFVlTfffBO5ubmoW7eu6ChEQmRlZWHWrFkYM2YM5s6dyxdfEhFZWJlLuL+/P/fOkmLk5ORg1KhRomMQCfH7779j3Lhx6NKlC+rUqcMCTkQkQJlL+PTp06syB5HF5OXl4eTJk/j8889FRyGyuLy8PEybNg2zZ89GcHCw6DhERFarXJco3LdvH9avX4+kpCR4e3vjlVdeQZcuXaoqG1GVSExMBAD4+fkJTkJkOQkJCYiKisL777+PmJgY2NjwXm1ERCKVuYQvXLgQ8+bNw7BhwxAQEIAbN27g1VdfxZQpU/Dee+9VZUbhtFqtxb5gqVQq5OXlwdbWFhqNPC/jbmNjAwcHB9ExSlWW+ZlMJjzzzDNwdHS0cLq/yHV+PPfMI9f5SZKEVatWYfbs2Xj//ffh6Ogoy+0ncp3f3/H8qzjOzjycnzKVeVr//ve/sW/fvmL7wl9//XUEBwcrvoTrdDqLPZetrS1cXV2Rm5sLg8FgsectDwcHB+Tn54uOUaqyzO/mzZvw8vIS9jHIdX4898wj1/nt378fX3/9NTZu3IiWLVtyfmbg+VdxnJ15OL/i3NzcLPI8Va1c37I0adKk2O8bNWokyxUVokeJjY3FM888IzoGUZU6cOAAcnNz0b17d3Ts2BF2dnaiIxER0d+UeY/FjBkzMHz4cFy5cgX5+fm4fPkyRo4ciZkzZ8JkMhX9RyR3586dQ/PmzUXHIKoSBQUFmD59Ot577z24uLhApVKxgBMRyVCZV8IjIyMBAOvXr4dKpYIkSQCAdevWITIyEpIkQaVSobCwsGqSElWSO3fu4IknnhAdg6hKfPLJJ8jIyEBMTIxifmRLRKREZS7hn3/+OV5++eUSj2/cuBEDBgyo1FBEVUWv1yMuLg7e3t6ioxBVGpPJhNWrVyM8PBzTp0+X7YsviYjo/5R5O8qnn34KHx+fEv/NmTOn2O+J5OzMmTMAAHd3d8FJiCrH3bt38frrr2Pjxo0oKChAjRo1WMCJiKqBx66E79u3DwBgNBqxf//+om0oAHD16lU4OztXXTqiSnbt2jU0bNhQdAyiSlFQUIDevXtj4MCBGDduHC8PRkRUjTz2X+zhw4cD+OsyfW+++WbR4yqVCnXq1MGSJUuqLh1RJfv55595gymq9vLy8rBz504MGDAAO3bs4E92iIiqoceW8GvXrgEAIiIisGrVqioPRFSVLl++jFGjRomOQVRhZ86cwZgxY9CqVSv06dOHBZyIqJoq888uWcCpujMYDEhJSUFAQIDoKEQVcuzYMYwcORKffvopevXqJToOERGZgRsIyWrs2bMHRqMR9vb2oqMQlcutW7dw7949tGrVCrt370bdunVFRyIiIjOV+eooRNVdXFwcBg4cKDoGUbls2bIFPXr0QGxsLGxtbVnAiYgUgivhZDWSk5PRpEkT0TGIymz+/Pn4+eefsXbtWt7llYhIYbgSTlZjw4YN8PDwEB2D6LFOnDiB/Px8DBo0CHv27GEBJyJSIJZwsir169cXHYHooQwGA+bNm4cRI0YgISEBPj4+cHBwEB2LiIiqALejkFXIz88HAPj6+gpOQlQ6vV6Pfv36wc3NDdHR0fypDRGRwrGEk1WIjY0FANSqVUtwEqLiJElCbGwsmjdvjunTp6NNmza87TwRkRVgCSerEBcXh5CQEJYbkpX09HRMmTIFt27dwvbt29G2bVvRkYiIyEK4J5yswo0bN+Dj4yM6BlGRuLg4BAcHw8fHB1u3boWtra3oSEREZEFcCSer8NVXX2HQoEGiYxChoKAAaWlp8PHxwZIlS9ChQwfRkYiISACuhJPVGDBggOgIZOUuXLiA8PBwrFq1Ck5OTizgRERWjCWcFC8zMxMA0Lp1a8FJyJr98MMPePnll/HWW2/h/fffFx2HiIgE43YUUrxvv/0WAKDVagUnIWt07949uLm5oWHDhti2bRsaNmwoOhIREckAV8JJ8VQqFby9vUXHICu0Z88edO3aFX/++Sfat2/PAk5EREUUsxKel5eHbdu2ISEhAY6OjujSpQtatGjx0OONRiOWLVsGvV6P9957z4JJydKuXr2Kvn37io5BVsRoNOLDDz/EoUOH8PXXX/PSg0REVIJiVsJ37twJtVqNSZMmoV+/ftixYwdSUlIeevzRo0dRo0YNCyYkUZKTk7kfnCwmOzsbGo0GzZs3R3R0NAs4ERGVShEr4Xq9HufPn8c777wDrVYLHx8f+Pr64syZMwgODi5xfEZGBs6ePYtu3bph27Ztxd6WnZ2NnJycEn++pQq7RqMp9qscqdVq2V7TuLT5HT16FIsXL5ZNZrnOj+eeeVQqFebNm4dly5bhyJEjePPNN0VHKkHO8+P5Zx65z4+zMw/np0yKmFhaWhpsbGxQu3btose8vLyQmJhY6vE7d+5Ely5dSj1hTpw4gQMHDhR7LDAwEEFBQZUb+jHc3Nws+nxK82B+D86BFi1ayPYfMLnhuVd+t27dwmuvvQYAOHToEOrXry84UfXF8888nF/FcXbm4fzKTxElXK/Xl7jyhb29PXQ6XYljL1y4AJPJBD8/P1y7dq3E21u3bg1fX98Sf35qamrlhn4IjUYDNzc3ZGRkwGg0WuQ5y0ur1ZY6Wzn45/z27duHTp06FV2mUA7kOj+eexVTUFCAzMxMdO3aFR988AGys7Mt9u9Feclxfg/w/DOP3OfH2ZmH8yvOw8PDIs9T1RRRwu3s7EqcnDqdrkQx1+v1iImJwZAhQx76Z7m4uMDFxaXYY0lJSTAYDJUXuAyMRqPFn7OsNBqNbLM98GB+iYmJ8PX1lVVeuc+P517ZZGdnY9q0aXBwcMD8+fMRGRkJtVrN+ZmJ8zOPXOfH2ZmH81MmRbww093dHSaTCWlpaUWPJScnl/hOKS0tDZmZmfj222+xYMECREVFIScnBwsWLEBGRoalY5MFxMbG8vKEVOmOHz+OkJAQ1KhRAzNmzBAdh4iIqiHFrIT7+flh//796NWrF5KTk3Hp0iUMHz682HGenp6YMGFC0e9v3ryJnTt3IjIykldKUaiYmBgMHDhQdAxSCKPRCLVajVu3bmHWrFkICQkRHYmIiKopRayEA0BYWBgMBgMWLFiAjRs3IiwsDJ6enkhMTMScOXMA/PXqYmdn56L/HBwcoFKp4OzsDBsbxYyC/ufOnTvIzs7G888/LzoKKcDVq1fRp08fHDx4EH379mUBJyIisyhiJRwAHB0dMXjw4BKP+/j4YNq0aaW+T8OGDXmjHgVLSUmBRqPhZZPILJIk4YcffsBnn32GCRMmoHPnzqIjERGRArCdkGJduXIFnTp1Eh2DqjFJkiBJEs6ePYuNGzeWuHISERFRRXEPBinWtWvXeKdMqrCDBw+iR48e0Ol0mDt3Lgs4ERFVKpZwUqyjR4+WuEwl0ePodDrMnDkTEyZMwAcffAAHBwfRkYiISIFYwkmx/vjjD/zxxx+iY1A1c/PmTaSkpCAmJob7v4mIqMpwTzgp2rvvvis6AlUDkiThu+++w/Xr1zFr1ix88cUXoiMREZHCsYSTIt25cwcA8PTTTwtOQnKXkpKCiRMnIiMjA0uWLBEdh4iIrAS3o5AirV+/Hm3btoWTk5PoKCRzmzZtQosWLbBlyxY0atRIdBwiIrISXAknRYqPj0fz5s1FxyCZysvLw6xZs9CzZ0+MGjVKdBwiIrJCXAknRYqLi0P79u1FxyAZOnv2LEJDQ5Gbm8tv1IiISBiuhJPiGAwGXLhwAa1atRIdhWRGkiTMmjULEydORJ8+fUTHISIiK8aVcFKc+/fvAwC8vb0FJyG5uH37Nt577z0UFBTgxx9/ZAEnIiLhWMJJca5duyY6AsnI1q1b0b17dzRs2BB2dnZQqVSiIxEREXE7CinPnTt38Oyzz4qOQTJw5coVLFy4EGvWrEGLFi1ExyEiIirCEk6Kc+vWLbi5uYmOQQIdP34cZ8+exfDhw7F3715oNPynjoiI5IXbUUhxDAYDGjZsKDoGCWAwGDB//ny89dZbaNCgAQCwgBMRkSzxqxMpjsFggK2tregYJMCyZctw9uxZREdHw9PTU3QcIiKih+JKOClOeno6CgoKRMcgC5EkCT/88AMuXLiAyMhIrF69mgWciIhkjyWcFGfOnDlYuXKl6BhkAenp6Rg5ciRWrFgBtVoNrVbLq58QEVG1wBJORNWSJEl4/fXXUa9ePfz8889o2rSp6EhERERlxj3hpDhDhw6Fv7+/6BhURXQ6HdatW4eIiAisX78eLi4uoiMRERGVG1fCSXFycnJYzBTqwoULCA8Px+HDh5Gfn8+/ZyIiqrZYwklxNm3ahMOHD4uOQZXs2rVr6NWrF4YNG4YVK1bAyclJdCQiIqIK43aUMtBqtbCxscz3KyqVCnl5ebC1tZXt9Y1tbGzg4OAgOkapHrwor7CwULYZ5To/uZ57d+/exdmzZxEcHIyjR4/Cw8NDdKRSyXV+fyfXcw/g/Mwl9/lxdubh/JSJ0yoDnU5nseeytbWFq6srcnNzYTAYLPa85eHg4ID8/HzRMUr14PrgkydPlm1Guc5PjudeTEwMpkyZgjfeeAOdOnWCh4eHLGcHyHN+/yTXcw/g/Mwl9/lxdubh/IpTyl2xWcJJUQoKCmBnZwdvb28YjUbRccgMq1atwhdffIHly5ejffv2ouMQERFVKpZwUpT09HTUrl2b14quxs6dOwd3d3eEhYWhT58+fPElEREpEl+YSYqSlpaG2rVri45BFVBYWIgvv/wSQ4YMQUJCAtzd3VnAiYhIsbgSToqSmZmpmL1i1kSSJAwfPhz379/Hzp07Ub9+fdGRiIiIqhRLOCmKXq+Hvb296BhUDsePH0ebNm0wefJkPP3001Cr1aIjERERVTluRyFF0ev1sLOzEx2DyuD+/fsYN24cJkyYgIyMDDzzzDMs4EREZDVYwklRDAYDtFqt6Bj0GLdv30ZISAi0Wi2io6NRq1Yt0ZGIiIgsittRSFGSkpJke51XAoxGI65du4bGjRtj4cKFeP7550VHIiIiEoIr4aQotra2cHd3Fx2DSnH9+nX06dMHixcvho2NDQs4ERFZNZZwUhRJkmR7a19rFh0djZ49e6JPnz5YtGiR6DhERETCcTsKKYokSbCx4feWcpGRkQGNRoNGjRphw4YN8PPzEx2JiIhIFthWSFFMJhPvlikThw8fRnBwMPbu3YsmTZqwgBMREf0NV8JJUbgSLg9z587Fxo0bsXDhQgQGBoqOQ0REJDtsK6QoXAkXKy0tDQDQvHlzxMTEsIATERE9BEs4KQpXwsWQJAnff/89goKCkJKSgvDwcF77m4iI6BG4HYUUhSvhlpeRkYFx48bh3r17+Omnn+Dp6Sk6EhERkeyxhJOicCXcsnJycuDg4IBOnTph2LBhsLW1FR2JiIioWmBbIUWRJIkr4RaQn5+PDz74ACNHjoS9vT1GjhzJAk5ERFQOLOGkKFwJr3qxsbEIDQ3F/fv3sXz5ctFxiIiIqiVuRyFFMZlMLOFVxGQywWQyITc3F+PGjUO/fv1ERyIiIqq2WMJJUbgSXjVu376N8ePHo2fPnoiIiBAdh4iIqNpjWyFF4dVRKt/27dvRvXt3vPDCCxgyZIjoOERERIqgmJXwvLw8bNu2DQkJCXB0dESXLl3QokWLEscdOXIEp0+fRlZWFhwdHdG2bVt07NhRQGKqClwJrzwPtvbEx8dj1apVePbZZ0VHIiIiUgzFlPCdO3dCrVZj0qRJSE5Oxrp161CnTp0S1yyWJAl9+/aFl5cXMjIysHr1ari4uKB58+aCklNl4kp45fjzzz8xadIkrFu3DhMmTBAdh4iISHEUsWSo1+tx/vx5BAUFQavVwsfHB76+vjhz5kyJYzt16gRvb2+o1WrUrl0bvr6+uHnzpoDUVFW4El5xRqMR8+fPx4gRIzB16lR4e3uLjkRERKRIilgJT0tLg42NDWrXrl30mJeXFxITEx/5fpIk4caNG2jdunXRY9nZ2cjJySl2nF6vR40aNSo39ENoNJpiv8qRWq2W9TWhVSoV51cBarUa2dnZuHHjBvbu3Ys6deqIjlSCXGcH8HPXXJyfeeQ+P87OPJyfMiliYnq9Hlqttthj9vb20Ol0j3y/X3/9FZIkISAgoOixEydO4MCBA8WOCwwMRFBQUOUFLgM3NzeLPp9SaLVa2NjYcH7lIEkSVq5ciS1btmDLli2IiooSHala47lnHs7PPJxfxXF25uH8yk8RJdzOzq5E4dbpdCWK+d8dO3YMZ86cwbBhw4p999a6dWv4+voWO1av1yM1NbVyQz+ERqOBm5sbMjIyYDQaLfKc5aXVah/7DY4oeXl5cHZ25vzKKCMjA5MmTUJ8fDy+/vrrosc4u/Lj5655OD/zyH1+nJ15OL/iPDw8LPI8VU0RJdzd3R0mkwlpaWlwd3cHACQnJ0yx2GwAAB4SSURBVD/0L+nkyZM4fPgwhg0bhpo1axZ7m4uLC1xcXIo9lpSUBIPBUDXhH8JoNFr8OctKo9HINlthYSFsbGw4vzI6cOAAPD098Z///AfOzs4AeO6Zi/MzD+dnHrnOj7MzD+enTIp4BZudnR38/Pywf/9+6PV63LhxA5cuXULLli1LHHv27Fns3bsXERERqFWrloC0VJV4dZTH0+l0mD17NtavX4+wsDDMmjUL9vb2omMRERFZFUWshANAWFgYtm7digULFsDBwQFhYWHw9PREYmIi1qxZg2nTpgEA9u3bh/z8fPz3v/8tet8WLVqgZ8+eoqJTJeJ1wh/typUrGD16NOrXr49Ro0aJjkNERGS1FFPCHR0dMXjw4BKP+/j4FBVwABg/frwlY5GFcSX80ZYuXYqhQ4fi1Vdf5ZyIiIgE4pIhKQ5XwotLTU3F6NGjkZSUhEWLFmHIkCEs4ERERIKxrZCicCW8uL1796Jbt26oX79+sevoExERkViK2Y5CBHBP+N9lZGTgs88+w5dffonnnntOdBwiIiL6G7YVUhSuhAOxsbGYPXs2XF1dERMTwwJOREQkQyzhpCjWvBJuMpmwfPlyvPrqq2jWrBlUKpXVzoKIiEjuuB2FFMWaV8K3b9+OPXv2YMeOHWjQoIHoOERERPQILOGkKNa4Ev7zzz/D3t4ePXv2RHh4ONRqtehIRERE9BjW1VZI8SRJspqV8JycHEyYMAFz585F7dq1YWNjwwJORERUTXAlnP5/e3cfVGWd/3/8dbg53CmICLi2irM5S5SppLZl3sSyqCtma9NqabnLWC3dTJOT29RaTc1+y+neKd2sca01xWYbLWPEUhNpvWMcCK282Q0dxCXIEDtxew6c6/eHv2hJVA5Hrus65zwf/5iHC683Ly46Lz58zkVQeeedd1RXV6dbbrnF6lH63MMPP6z+/ftr69atiouLs3ocAADgA0o4gs7WrVutHqHPtLe3a9WqVZo3b56WLVummJgYq0cCAAC9wHYUIEBUVVXplltu0c6dO9XW1kYBBwAggFHCgQDgcrk0e/ZszZw5UwUFBUpOTrZ6JAAA4Ae2owA2dubMGW3fvl233nqrtm/froEDB1o9EgAAuARYCUfQCZa7o+zevVs5OTk6ePCgDMOggAMAEERYCUfQCYb7hG/btk2PPvqoXnzxRWVlZVk9DgAAuMQo4Qg6gVzCv/rqK7W2tmrSpEnaunWrkpKSrB4JAAD0gcBtK8B5BGIJNwxD//jHPzR79mxVVlYqOjqaAg4AQBBjJRxBJxB/a+SSJUtUXl6u999/XyNGjLB6HAAA0Mco4Qg6gbQSvmfPHo0bN0733HOPhgwZIqfTafVIAADABIHTVoAeCoQS3tLSoiVLluihhx7SyZMnNXz4cAo4AAAhxP5tBfCR3Ut4U1OTZsyYodOnT2vbtm36xS9+YfVIAADAZGxHQdCZPn261SN0y+v16vPPP9d1112nl156SZmZmUFzT3MAAOAbh2EYhtVD2F19fb1pq6sOh0NOp1Nut1t2/dSEhYXJ6/VaPUa3fv/73+v+++9XVlaWrfKrqanR/fffL6/Xq02bNlk9Tre49vxDfv4hP//YPT+y8w/5dZWYmGjKefoaK+E90NbWZtq5IiMjNWDAADU1Ncnj8Zh2Xl/ExMSopaXF6jG65fV6FRMTI4/HY5v89u/fr7vuukt5eXl64IEHJMmW+XHt+Yf8/EN+/rF7fmTnH/LrihIO2JCdVjEaGxv1/fffa8SIEXr77beVmZlp9UgAAMAm7P0KNsBHhmHYYp91WVmZpk2bpg8++ECJiYkUcAAA0AUr4Qg6VpfwN998UytWrNDSpUs1Y8YMS2cBAAD2RAlHULFyO0ptba1SU1M1cuRIffTRR/rZz35m2SwAAMDe2I6CoGLFdhTDMPTee+8pJydHX375pSZMmEABBwAAF8RKOIKOmSW8tbVVixYt0pEjR/Tuu+/qqquuMu3cAAAgcLESDvTSmTNnFBUVpQkTJqioqIgCDgAAeowSjqDT1yvhbrdbzz77rGbPni2v16s777xTMTExfXpOAAAQXCjhCCp9/cLM48ePa9asWfr3v/+t9957T+Hh4X16PgAAEJzYE46g0lcvzDQMQ62trQoPD9f8+fN1xx13WH4rRAAAELhYCUfQudTl+Ntvv1VeXp5efvllDRs2THfeeScFHAAA+IUSjqByqbejFBcXa+rUqUpPT9ef//znS/pvAwCA0MV2FASVS7Udpb29XREREfrmm2+0fPlyTZgw4RJMBwAAcBYr4Qg6/pbwL7/8UlOnTlV5ebnmzp1LAQcAAJccJRxBxZ/tKF6vVytXrtRtt92m++67T5mZmZdwMgAAgB+xHQVBpbfbUQzDUEdHh6qqqrR582YNGzasD6YDAAA4i5VwBB1fS/jmzZs1c+ZMSdLSpUsp4AAAoM+xEo6g4st2lKamJj355JPat2+fXn31VUVGRvbhZAAAAD+ihCOo+LId5fjx43I4HPr444/Vr1+/Pp4MAADgR5RwBJ0LlfCOjg699tpram1t1aOPPqoXX3zRxMkAAADOooQjqFxoO8qJEyf04IMPyul0atmyZSZOBQAA0BUlHEHnfCvh7733nqZPn6577rlHYWG8JhkAAFiHEo6g8tOV8O+++06PP/64Fi5cqIcfftiiqQAAALoKmhLe3NysDz/8UJWVlYqNjVV2drZGjRp1znGGYWj79u0qLy+XJGVmZionJ+eS/Kpz2MMPn8t9+/bpwQcfVE5OjtLT0y2eCgAA4EdBU8KLiooUHh6uxYsXq7a2VgUFBRo8eLBSUlK6HFdWVqYjR44oPz9fDodDa9asUWJiosaPH2/R5LjUHA6H2tvb9dxzz2np0qXKzs62eiQAAIAugqKEu91uHTp0SPfdd5+ioqKUlpam9PR0HThwQDk5OV2Oraio0PXXX6+EhARJ0oQJE1RWVtZZwl0ulxobG8/59+Pi4kz5WCIiIrr8aUfh4eG2vad2S0uL/vrXv2r16tUqLCy05U847Jof155/yM8/5Ocfu+dHdv4hv+AUFInV19crLCxMgwYN6nwsNTVVVVVV5xx76tQpDR48uMtxp06d6vx7WVmZSkpKurzPlClTlJWV1QeTn19iYqKp5wt0hmHozTff1LFjx3TrrbcqJSXFlgU8EHDt+Yf8/EN+/iG/3iM7/5Cf74KihLvdbkVFRXV5LDo6Wm1tbRc9Njo6Wm63u/OXvIwdO/ac/cNut7tLUe9LERERSkxMVENDg9rb2005p6+ioqK6zdZK5eXlWrFihYqLi3XdddeRXy9w7fmH/PxDfv6xe35k5x/y6yo5OdmU8/S1oCjhTqfznIuzra3tnGLe3bFtbW1yOp2dq6bx8fGKj4/v8j41NTXyeDx9MPn5tbe3m37OnoqIiLDNbMXFxaqurtaCBQu0efNmRUdHSyI/f5Cdf8jPP+TnH7vmR3b+Ib/gFBQ3S05KSpLX61V9fX3nY7W1td1+p5ScnKy6urqLHgd7a2lp0ZNPPqlHHnlEl19+uaSze+YAAAACQVCUcKfTqYyMDBUXF8vtduvEiRM6evSoRo8efc6xo0eP1t69e+VyueRyubR3716NGTPGgqnhj5dffll1dXXatm2bbrjhBqvHAQAA8ElQbEeRpNzcXG3atEkvvPCCYmJilJubq5SUFFVVVWnt2rVasmSJJGncuHFqaGjQ3/72N0nSNddco3Hjxlk5OnrI6/Vq9erVys7O1uLFi7tsIwIAAAgkQVPCY2Njdfvtt5/zeFpaWmcBl87eQ3rq1KmaOnWqmePBT7W1tXrooYfU3NysadOmdbvfHwAAIFAExXYUBLeOjg7dfvvtuvbaa7Vx40YNHTrU6pEAAAD8EjQr4Qg+TU1NKigo0MKFC1VYWKh+/fpZPRIAAMAlwUo4bOmzzz7T1KlTdfjwYbndbgo4AAAIKqyEw3a++OIL/fGPf9QzzzyjmTNnWj0OAADAJUcJh21UV1fr2LFjmjx5snbs2KGkpCSrRwIAAOgTbEeB5QzD0IYNGzRjxgwdP35cDoeDAg4AAIIaK+Gw3PLly7VhwwatX79eI0eOtHocAACAPsdKOCxTWlqq+vp6zZ07V1u2bKGAAwCAkEEJh+ncbreWLl2q/Px8VVVVKSUlRTExMVaPBQAAYBq2o8BUXq9Xc+fOVb9+/bR161YlJydbPRIAAIDpKOEwhWEY2rdvn66//no9++yzuuKKK+RwOKweCwAAwBKUcPS506dPa/Hixfrvf/+rjRs3KiMjw+qRAAAALMWecPSpr776Sjk5Obr88stVWFiouLg4q0cCAACwHCvh6BOtra06efKk0tLS9MYbb2jcuHFWjwQAAGAbrITjkjt8+LByc3O1Zs0aRUZGUsABAAB+ghKOS2rDhg2aM2eO/vSnP+npp5+2ehwAAABbYjsKLom6ujrFx8frqquuUmFhoYYPH271SAAAALbFSjj8tmXLFk2bNk179uzRFVdcQQEHAAC4CFbC0WuGYejRRx/Vv/71L61atYq93wAAAD3ESjh65dSpU3I4HJo4caI+/vhjCjgAAIAPKOHwSUdHh1566SVNmzZNLpdLN910k/r372/1WAAAAAGF7Sjosbq6Ot17772KjIxUYWGh4uPjrR4JAAAgIDkMwzCsHsLu6uvrFRZmzg8NHA6HnE6n3G637PSpcblccjgc+uc//6mFCxdaPc552TW//xUWFiav12v1GOcgO/+Qn3/Izz92z4/s/EN+XSUmJppynr7GSngPtLW1mXauyMhIDRgwQE1NTfJ4PKad93xcLpf+8pe/yOPx6I033tC8efMkSS0tLRZP1j275dedmJgYW+ZHdv4hP/+Qn3/snh/Z+Yf8ugqWEs6ecJzX/v37lZOTo/j4eC1btszqcQAAAIIGK+E4h8fjUVhYmFpaWvR///d/ysnJsXokAACAoMJKOLqorKzUzTffrMLCQk2ePJkCDgAA0Aco4ZB09hfvFBQU6He/+53mzJmjm2++2eqRAAAAghbbUaCOjg6Fh4erpqZGGzZs0C9/+UurRwIAAAhqrISHuJKSEt14441qaGjQ4sWLKeAAAAAmYCU8RLW2tmrp0qXavHmzXnnllaC53Q8AAEAgoISHIMMw5HK51NTUpG3btlHAAQAATMZ2lBDi9Xq1atUqPfDAA0pJSdGLL75IAQcAALAAK+Ehoq6uTosWLdL333+v1157zepxAAAAQhor4SGipKREY8eO1fvvv6/hw4dbPQ4AAEBIYyU8iDU3N+upp57SxIkTNWfOHKvHAQAAwP/HSniQqqio0NSpU9XW1qasrCyrxwEAAMD/YCU8SK1cuVKPPPKIZs2aZfUoAAAA+AlWwoPIyZMndffdd+v06dNauXIlBRwAAMCmKOFB4oMPPtCMGTOUmZmphIQEq8cBAADABbAdJQjU1NTo9ddf17p163T11VdbPQ4AAAAughIewEpLS7Vjxw499thj+uijj+RwOKweCQAAAD3AdpQA5PF49Nxzzyk/P19jx46VJAo4AABAAGElPACtX79eX3zxhT7++GOlpKRYPQ4AAAB8RAkPEIZhaP369Ro2bJjmz5+vO++8k9VvAACAAMV2lABw+vRp3X333Vq9erWSk5MVHh5OAQcAAAhgAb8S3tzcrA8//FCVlZWKjY1Vdna2Ro0a1e2xu3fvVkVFhb777jvFxsZq/PjxuuGGG0ye2HcPPPCArrjiCq1YsUJRUVFWjwMAAAA/BXwJLyoqUnh4uBYvXqza2loVFBRo8ODB3e6VNgxDs2fPVmpqqhoaGvTOO+8oPj7elrf1a21t1YoVK3TXXXfp73//u2JiYqweCQAAAJdIQG9HcbvdOnTokLKyshQVFaW0tDSlp6frwIED3R4/ceJEDRkyROHh4Ro0aJDS09NVXV1t8tQX98UXX2jatGn6/PPP5fF4KOAAAABBJqBXwuvr6xUWFqZBgwZ1PpaamqqqqqqLvq9hGDpx4kTnLf5+4HK51NjY2OUxt9utuLi4SzP0RZw+fVrZ2dl6/PHHNXfuXFvu/Q4PD1dkZKTVY3QrIiKiy592ZNf8yM4/5Ocf8vOP3fMjO/+QX3AK6MTcbvc5e6Sjo6PV1tZ20ffduXOnDMNQZmZml8fLyspUUlLS5bEpU6YoKyvL/4F7IDk5WUePHtWAAQNMOV+wSkxMtHqEgEV2/iE//5Cff8iv98jOP+TnO1uX8Lfeeuu8q9pDhw7VjBkzzincbW1tF33xYmlpqQ4cOKC8vLxzvnMbO3as0tPTuzzmdrt16tSpXnwEvouIiFBiYqIaGhrU3t5uyjl9FRUV1aNvdKxAfr1Hdv4hP/+Qn3/snh/Z+Yf8ukpOTjblPH3N1iU8Ly/vgm93u93yer2qr69XUlKSJKm2tvaCn5zy8nLt2rVLeXl5SkhIOOft8fHxio+P7/JYTU2NPB5PLz6C3mtvbzf9nD0VERFh29l+QH69R3b+IT//kJ9/7Jof2fmH/IJTQL8w0+l0KiMjQ8XFxXK73Tpx4oSOHj2q0aNHd3v8wYMH9cknn2jBggUaOHCgydMCAAAAZ9l6JbwncnNztWnTJr3wwguKiYlRbm5u5+0Jq6qqtHbtWi1ZskSStGPHDrW0tOjNN9/sfP9Ro0bppptusmR2AAAAhKaAL+GxsbG6/fbbu31bWlpaZwGXpIceesissQAAAIDzCujtKAAAAEAgooQDAAAAJqOEAwAAACajhAMAAAAmo4QDAAAAJqOEAwAAACajhAMAAAAmo4QDAAAAJqOEAwAAACajhAMAAAAmo4QDAAAAJqOEAwAAACajhAMAAAAmo4QDAAAAJnMYhmFYPQR+5HK5VFZWprFjxyo+Pt7qcQIO+fUe2fmH/PxDfv4hv94jO/+QX++xEm4zjY2NKikpUWNjo9WjBCTy6z2y8w/5+Yf8/EN+vUd2/iG/3qOEAwAAACajhAMAAAAmo4QDAAAAJgt/6qmnnrJ6CPzIMAw5nU4NHz5cUVFRVo8TcMiv98jOP+TnH/LzD/n1Htn5h/x6j7ujAAAAACaLsHoASM3Nzfrwww9VWVmp2NhYZWdna9SoUd0eu3v3blVUVOi7775TbGysxo8frxtuuMHkia3V07wMw9D27dtVXl4uScrMzFROTo4cDofZI9tKT/PjWuueL1+vktTe3q7XX39dbrdbDz/8sImT2o8v2dXU1Oijjz7S119/LafTqUmTJum6664zeWJ76Wl+7e3t2rJli44cOaKOjg4NGzZMM2fODOnbx5WWlqqiokLffPONRo4cqdmzZ5/32L1792rXrl1qb29XRkaGZs6cqYiI0K5LPc2voqJCpaWlqq+vV1RUlK6++mplZ2crPDzc5IkDQ2hfVTZRVFSk8PBwLV68WLW1tSooKNDgwYOVkpJyzrGGYWj27NlKTU1VQ0OD3nnnHcXHx+vqq6+2YHJr9DSvsrIyHTlyRPn5+XI4HFqzZo0SExM1fvx4iya3h57mx7XWPV++XiVpz549iouLk9vtNnlS++lpdk1NTVq7dq2mT5+uK6+8Uh0dHXK5XBZNbR89zW/fvn06efKk7r33XkVFRamwsFBFRUW67bbbLJrcev3799fkyZNVWVkpj8dz3uO++uor7dq1S3/4wx/Uv39/vfvuuyouLlZOTo6J09pPT/PzeDyaPn26LrvsMjU3N2v9+vXas2ePJk2aZOK0gYMXZlrM7Xbr0KFDysrKUlRUlNLS0pSenq4DBw50e/zEiRM1ZMgQhYeHa9CgQUpPT1d1dbXJU1vHl7wqKip0/fXXKyEhQfHx8ZowYYIqKiosmNo+fMkv1K+17vj69drQ0KCDBw/yBCTfstu7d69GjBihUaNGKSIiQlFRUUpOTrZgavvwJb8zZ87o8ssvV79+/RQZGamRI0fq1KlTFkxtH1deeaUyMjIUExNzweMqKiqUmZmplJQUxcTEaMqUKSH/vCH1PL/x48crLS1NERERnYs2of68cSGUcIvV19crLCxMgwYN6nwsNTW1R//DNAxDJ06cCKknJ1/yOnXqlAYPHnzR40JJb6+3ULzWuuNrfkVFRcrOzg75H2VLvmV38uRJxcTEaNWqVXr++edVUFCgM2fOmDmu7fiSX2Zmpqqrq+VyueR2u3Xw4EGNGDHCzHEDVnfPG01NTWpubrZwqsBVVVUV8s8bF0IJt5jb7T7n1cTR0dFqa2u76Pvu3LlThmEoMzOzr8azHV/y+umx0dHRcrvdCuXXIvf2egvFa607vuR3+PBheb1eZWRkmDWerfmSncvlUkVFhX77299q0aJFGjBggDZs2GDWqLbkS35JSUlKSEjQyy+/rKVLl+rbb7/VlClTzBo1oHX3vCGpR8/J6Oqzzz5TTU2NJkyYYPUotsXyTB976623VFVV1e3bhg4dqhkzZpzzxd3W1nbR2/yUlpbqwIEDysvLC6lVNqfT2eO8fnpsW1ubnE5nSL8w05f8fhCq11p3epqf2+3Wtm3bNH/+fDPHszVfrr3IyEhlZGTosssukyTdeOONev7559Xa2tpZikKNL/lt3rxZ7e3teuSRR+R0OrV7926tW7dOd999t1njBqzunjckces9Hx0+fFjbt2/XggULFBcXZ/U4thXaz6gmyMvLu+Db3W63vF6v6uvrlZSUJEmqra294I9vysvLtWvXLuXl5SkhIeGSzmt3SUlJPc4rOTlZdXV1+vnPf37B40KJL/lJoX2tdaen+dXX1+vMmTNavXq1JKmjo0NtbW164YUXdNdddykxMdH02a3my7WXmpra7b8Ryj/F8iW/2tpaZWdnKzY2VpJ07bXXqri4WE1NTRSii/jheWPkyJGSzmYZFxfXmSUu7j//+Y8KCws1b968834t4yy2o1jM6XQqIyNDxcXFcrvdOnHihI4eParRo0d3e/zBgwf1ySefaMGCBRo4cKDJ01rPl7xGjx6tvXv3yuVyyeVyae/evRozZowFU9uHL/mF+rXWnZ7ml5KSokWLFik/P1/5+fmaNWuW4uLilJ+fH7LfzPhy7Y0ZM0ZHjhzR119/rY6ODn366acaNmzYRV8UFsx8ye+yyy7TgQMH1Nraqo6ODu3fv1/9+/cP6QLe0dEhj8cjwzBkGIY8Ho86OjrOOW706NEqLy/XN998o5aWFn366ach/7wh9Ty/Y8eOaePGjZozZ07nAhjOj1/WYwPNzc3atGmTjh07ppiYGP3mN7/pvPdrVVWV1q5dqyVLlkiSli1bJpfL1eWem6NGjdJNN91kyexWOF9eP83KMAxt27at8z7h11xzDfcJV8/z41rrXk/z+1/Hjx/Xxo0buU+4D9nt379fn376qTwej4YNG6bc3NyQ/QbmBz3Nr7m5WVu2bFFlZaU6OjqUkpKiadOmhXQpKi4uVklJSZfHpkyZoszMTK1YsUL333+/BgwYIOnsbUV3794tj8ejK6+8kvuEq+f5vf3226qqquqSV1pamu644w6zRw4IlHAAAADAZGxHAQAAAExGCQcAAABMRgkHAAAATEYJBwAAAExGCQcAAABMRgkHAAAATEYJBwAAAExGCQcAAABMRgkHAAAATEYJBwAAAExGCQcAAABMRgkHAAAATEYJBwAAAExGCQcAAABMRgkHAAAATEYJBwAAAExGCQeAAHD06FFlZmaqf//+evXVV60eBwDgJ4dhGIbVQwAALmzhwoWKj4/XK6+8YvUoAIBLgJVwAAgAVVVVuuqqq3x+v/b29j6YBgDgL1bCAcDmfv3rX6ukpESRkZGKiIjQrFmzFB8fr8rKSu3bt0/XXHON1qxZo7S0NEmSw+HQ8uXLtWzZMrW3t+v48eMWfwQAgJ9iJRwAbG7Hjh2aNGmSli9frsbGRjmdTq1bt05PPPGEvv32W40ZM0bz58/v8j4ffPCBSktLdejQIYumBgBcSITVAwAAfJebm6vJkydLkp555hklJCSourpaQ4cOlSQ99thjGjhwoJUjAgAugJVwAAhAP5RtSerXr58GDhyompqabt8OALAfSjgABKDq6urO/25sbNTp06c1ZMiQzsccDocVYwEAeogSDgABqKioSLt27ZLb7dYTTzyhX/3qV6x+A0AAoYQDQACaN2+enn76aQ0cOFBlZWVat26d1SMBAHzACzMBIADs3Lmzy98HDRqklStXdnssd54FAPtjJRwAAAAwGSUcAAAAMBm/MRMAAAAwGSvhAAAAgMko4QAAAIDJKOEAAACAySjhAAAAgMko4QAAAIDJKOEAAACAyf4f30zlTspg/MIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 792x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<ggplot: (29732328)>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs =  GBC.best_estimator_.predict_proba(X_test)\n",
    "preds = probs[:,1]\n",
    "fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "df = pd.DataFrame(dict(fpr = fpr, tpr = tpr))\n",
    "ggplot(df, aes(x = 'fpr', y = 'tpr')) + geom_line() + geom_abline(linetype = 'dashed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f) For your best performing model, plot out a ROC curve using your test data. Feel free to use sklearn, matplotlib or any other method in python. Describe what the x-axis & y-axis of the ROC curve tell us about a classifier.\n",
    "The y-axis for the ROC curve is the true positive rate (True positives / Total population positives) while the x axis is the false positive rate. The equation for FPR is a bit trickier. FPR = 1 - specificity....  1 - (True negatives / Total population negatives). The decimal returned by the roc curve looks at the probability that the model will be able to determine class seperation. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
