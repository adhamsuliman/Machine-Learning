{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix, classification_report\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (507, 148)\n",
      "Test shape: (168, 148)\n"
     ]
    }
   ],
   "source": [
    "#a)\n",
    "train = pd.read_csv(r'C:\\Users\\u353822\\Documents\\GitHub\\University-of-Chicago1\\University of Chicago\\Machine Learning\\HW6\\train_data.csv')\n",
    "test = pd.read_csv(r'C:\\Users\\u353822\\Documents\\GitHub\\University-of-Chicago1\\University of Chicago\\Machine Learning\\HW6\\test_data.csv')\n",
    "print('Train shape: {}'.format(train.shape))\n",
    "print('Test shape: {}'.format(test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>BrdIndx</th>\n",
       "      <th>Area</th>\n",
       "      <th>Round</th>\n",
       "      <th>Bright</th>\n",
       "      <th>Compact</th>\n",
       "      <th>ShpIndx</th>\n",
       "      <th>Mean_G</th>\n",
       "      <th>Mean_R</th>\n",
       "      <th>Mean_NIR</th>\n",
       "      <th>...</th>\n",
       "      <th>SD_NIR_140</th>\n",
       "      <th>LW_140</th>\n",
       "      <th>GLCM1_140</th>\n",
       "      <th>Rect_140</th>\n",
       "      <th>GLCM2_140</th>\n",
       "      <th>Dens_140</th>\n",
       "      <th>Assym_140</th>\n",
       "      <th>NDVI_140</th>\n",
       "      <th>BordLngth_140</th>\n",
       "      <th>GLCM3_140</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>concrete</td>\n",
       "      <td>1.32</td>\n",
       "      <td>131</td>\n",
       "      <td>0.81</td>\n",
       "      <td>222.74</td>\n",
       "      <td>1.66</td>\n",
       "      <td>2.18</td>\n",
       "      <td>192.94</td>\n",
       "      <td>235.11</td>\n",
       "      <td>240.15</td>\n",
       "      <td>...</td>\n",
       "      <td>31.15</td>\n",
       "      <td>5.04</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.58</td>\n",
       "      <td>8.56</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.98</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>1512</td>\n",
       "      <td>1287.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>shadow</td>\n",
       "      <td>1.59</td>\n",
       "      <td>864</td>\n",
       "      <td>0.94</td>\n",
       "      <td>47.56</td>\n",
       "      <td>1.41</td>\n",
       "      <td>1.87</td>\n",
       "      <td>36.82</td>\n",
       "      <td>48.78</td>\n",
       "      <td>57.09</td>\n",
       "      <td>...</td>\n",
       "      <td>12.01</td>\n",
       "      <td>3.70</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.96</td>\n",
       "      <td>7.01</td>\n",
       "      <td>1.69</td>\n",
       "      <td>0.86</td>\n",
       "      <td>-0.14</td>\n",
       "      <td>196</td>\n",
       "      <td>2659.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>shadow</td>\n",
       "      <td>1.41</td>\n",
       "      <td>409</td>\n",
       "      <td>1.00</td>\n",
       "      <td>51.38</td>\n",
       "      <td>1.37</td>\n",
       "      <td>1.53</td>\n",
       "      <td>41.72</td>\n",
       "      <td>51.96</td>\n",
       "      <td>60.48</td>\n",
       "      <td>...</td>\n",
       "      <td>18.75</td>\n",
       "      <td>3.09</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.63</td>\n",
       "      <td>8.32</td>\n",
       "      <td>1.38</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1198</td>\n",
       "      <td>720.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tree</td>\n",
       "      <td>2.58</td>\n",
       "      <td>187</td>\n",
       "      <td>1.91</td>\n",
       "      <td>70.08</td>\n",
       "      <td>3.41</td>\n",
       "      <td>3.11</td>\n",
       "      <td>93.13</td>\n",
       "      <td>55.20</td>\n",
       "      <td>61.92</td>\n",
       "      <td>...</td>\n",
       "      <td>27.67</td>\n",
       "      <td>6.33</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.70</td>\n",
       "      <td>8.56</td>\n",
       "      <td>1.10</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.20</td>\n",
       "      <td>524</td>\n",
       "      <td>891.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>asphalt</td>\n",
       "      <td>2.60</td>\n",
       "      <td>116</td>\n",
       "      <td>2.05</td>\n",
       "      <td>89.57</td>\n",
       "      <td>3.06</td>\n",
       "      <td>3.02</td>\n",
       "      <td>73.17</td>\n",
       "      <td>94.89</td>\n",
       "      <td>100.64</td>\n",
       "      <td>...</td>\n",
       "      <td>32.05</td>\n",
       "      <td>1.01</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.75</td>\n",
       "      <td>8.62</td>\n",
       "      <td>2.08</td>\n",
       "      <td>0.08</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>496</td>\n",
       "      <td>1194.76</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 148 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       class  BrdIndx  Area  Round  Bright  Compact  ShpIndx  Mean_G  Mean_R  \\\n",
       "0  concrete      1.32   131   0.81  222.74     1.66     2.18  192.94  235.11   \n",
       "1    shadow      1.59   864   0.94   47.56     1.41     1.87   36.82   48.78   \n",
       "2    shadow      1.41   409   1.00   51.38     1.37     1.53   41.72   51.96   \n",
       "3      tree      2.58   187   1.91   70.08     3.41     3.11   93.13   55.20   \n",
       "4   asphalt      2.60   116   2.05   89.57     3.06     3.02   73.17   94.89   \n",
       "\n",
       "   Mean_NIR    ...      SD_NIR_140  LW_140  GLCM1_140  Rect_140  GLCM2_140  \\\n",
       "0    240.15    ...           31.15    5.04       0.80      0.58       8.56   \n",
       "1     57.09    ...           12.01    3.70       0.52      0.96       7.01   \n",
       "2     60.48    ...           18.75    3.09       0.90      0.63       8.32   \n",
       "3     61.92    ...           27.67    6.33       0.89      0.70       8.56   \n",
       "4    100.64    ...           32.05    1.01       0.83      0.75       8.62   \n",
       "\n",
       "   Dens_140  Assym_140  NDVI_140  BordLngth_140  GLCM3_140  \n",
       "0      0.82       0.98     -0.10           1512    1287.52  \n",
       "1      1.69       0.86     -0.14            196    2659.74  \n",
       "2      1.38       0.84      0.10           1198     720.38  \n",
       "3      1.10       0.96      0.20            524     891.36  \n",
       "4      2.08       0.08     -0.10            496    1194.76  \n",
       "\n",
       "[5 rows x 148 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#b)\n",
    "train = train.dropna(how='any')\n",
    "test = test.dropna(how='any')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#c) \n",
    "X_train = train.drop('class',axis=1)\n",
    "y_train = train['class']\n",
    "X_test = test.drop('class',axis=1)\n",
    "y_test = test['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#d)\n",
    "sc = StandardScaler()\n",
    "X_train_sc = sc.fit_transform(X_train)\n",
    "X_test_sc = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Part 2)\n",
    "#a)\n",
    "RFC = RandomForestClassifier()\n",
    "RFC.fit(X_train_sc,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[14  0  0  0  0  0  0  0  0]\n",
      " [ 1 21  0  3  0  0  0  0  0]\n",
      " [ 0  1 14  0  0  0  0  0  0]\n",
      " [ 0  4  0 19  0  0  0  0  0]\n",
      " [ 0  0  0  0 28  0  0  0  1]\n",
      " [ 1  0  1  0  0 13  0  0  0]\n",
      " [ 1  0  0  0  0  0 15  0  0]\n",
      " [ 0  1  0  6  2  0  0  5  0]\n",
      " [ 0  0  0  1  1  0  0  0 15]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   asphalt        0.82      1.00      0.90        14\n",
      "  building        0.78      0.84      0.81        25\n",
      "       car        0.93      0.93      0.93        15\n",
      "  concrete        0.66      0.83      0.73        23\n",
      "     grass        0.90      0.97      0.93        29\n",
      "      pool        1.00      0.87      0.93        15\n",
      "    shadow        1.00      0.94      0.97        16\n",
      "      soil        1.00      0.36      0.53        14\n",
      "      tree        0.94      0.88      0.91        17\n",
      "\n",
      "avg / total       0.88      0.86      0.85       168\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#b & c)\n",
    "y_pred = RFC.predict(X_test_sc)\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[45  0  0  0  0  0  0  0  0]\n",
      " [ 0 96  0  1  0  0  0  0  0]\n",
      " [ 0  0 21  0  0  0  0  0  0]\n",
      " [ 0  3  0 90  0  0  0  0  0]\n",
      " [ 0  0  0  0 82  0  0  0  1]\n",
      " [ 0  0  0  0  0 14  0  0  0]\n",
      " [ 0  0  0  0  0  0 45  0  0]\n",
      " [ 0  2  0  1  0  0  0 17  0]\n",
      " [ 0  0  0  0  2  0  0  0 87]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   asphalt        1.00      1.00      1.00        45\n",
      "  building        0.95      0.99      0.97        97\n",
      "       car        1.00      1.00      1.00        21\n",
      "  concrete        0.98      0.97      0.97        93\n",
      "     grass        0.98      0.99      0.98        83\n",
      "      pool        1.00      1.00      1.00        14\n",
      "    shadow        1.00      1.00      1.00        45\n",
      "      soil        1.00      0.85      0.92        20\n",
      "      tree        0.99      0.98      0.98        89\n",
      "\n",
      "avg / total       0.98      0.98      0.98       507\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#d)\n",
    "y_pred_train = RFC.predict(X_train_sc)\n",
    "print(confusion_matrix(y_train, y_pred_train))\n",
    "print(classification_report(y_train, y_pred_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Bright_40</th>\n",
       "      <td>0.061383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NDVI_40</th>\n",
       "      <td>0.047206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NDVI</th>\n",
       "      <td>0.039610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean_R_40</th>\n",
       "      <td>0.037660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NDVI_60</th>\n",
       "      <td>0.037371</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           importance\n",
       "Bright_40    0.061383\n",
       "NDVI_40      0.047206\n",
       "NDVI         0.039610\n",
       "Mean_R_40    0.037660\n",
       "NDVI_60      0.037371"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(RFC.feature_importances_,index = X_train.columns,\n",
    "        columns=['importance']).sort_values('importance',ascending=False).iloc[:5,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# part 3\n",
    "#a)\n",
    "LSVC = LinearSVC()\n",
    "LSVC.fit(X_train_sc, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#b)\n",
    "y_pred = LSVC.predict(X_test_sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "   asphalt        0.76      0.93      0.84        14\n",
      "  building        0.65      0.88      0.75        25\n",
      "       car        0.86      0.80      0.83        15\n",
      "  concrete        0.79      0.65      0.71        23\n",
      "     grass        0.72      0.90      0.80        29\n",
      "      pool        1.00      0.87      0.93        15\n",
      "    shadow        0.93      0.88      0.90        16\n",
      "      soil        1.00      0.43      0.60        14\n",
      "      tree        0.71      0.59      0.65        17\n",
      "\n",
      "avg / total       0.80      0.78      0.77       168\n",
      "\n",
      "[[13  0  0  0  0  0  1  0  0]\n",
      " [ 0 22  1  1  1  0  0  0  0]\n",
      " [ 0  2 12  0  0  0  0  0  1]\n",
      " [ 1  6  0 15  0  0  0  0  1]\n",
      " [ 0  0  0  1 26  0  0  0  2]\n",
      " [ 1  0  1  0  0 13  0  0  0]\n",
      " [ 2  0  0  0  0  0 14  0  0]\n",
      " [ 0  4  0  1  3  0  0  6  0]\n",
      " [ 0  0  0  1  6  0  0  0 10]]\n"
     ]
    }
   ],
   "source": [
    "#c)\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(confusion_matrix(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "   asphalt        1.00      1.00      1.00        45\n",
      "  building        0.99      1.00      0.99        97\n",
      "       car        1.00      1.00      1.00        21\n",
      "  concrete        1.00      1.00      1.00        93\n",
      "     grass        1.00      0.96      0.98        83\n",
      "      pool        1.00      1.00      1.00        14\n",
      "    shadow        1.00      1.00      1.00        45\n",
      "      soil        1.00      1.00      1.00        20\n",
      "      tree        0.98      1.00      0.99        89\n",
      "\n",
      "avg / total       0.99      0.99      0.99       507\n",
      "\n",
      "[[45  0  0  0  0  0  0  0  0]\n",
      " [ 0 97  0  0  0  0  0  0  0]\n",
      " [ 0  0 21  0  0  0  0  0  0]\n",
      " [ 0  0  0 93  0  0  0  0  0]\n",
      " [ 0  1  0  0 80  0  0  0  2]\n",
      " [ 0  0  0  0  0 14  0  0  0]\n",
      " [ 0  0  0  0  0  0 45  0  0]\n",
      " [ 0  0  0  0  0  0  0 20  0]\n",
      " [ 0  0  0  0  0  0  0  0 89]]\n"
     ]
    }
   ],
   "source": [
    "#d)\n",
    "y_pred_train = LSVC.predict(X_train_sc)\n",
    "print(classification_report(y_train, y_pred_train))\n",
    "print(confusion_matrix(y_train, y_pred_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There does seem to be overfitting because our model returns an accuracy of 99% for our train data while the model return an accuracy of around 80% for our test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'C': array([1.000e-02, 2.100e-01, 4.100e-01, 6.100e-01, 8.100e-01, 1.010e+00,\n",
       "       1.210e+00, 1.410e+00, 1.610e+00, 1.810e+00, 2.010e+00, 2.210e+00,\n",
       "       2.410e+00, 2.610e+00, 2.810e+00, 3.010e+00, 3.210e+00, 3.410e+00,\n",
       "       3.610e+00, 3.810e+00, 4.010e+00, 4.210e+00, 4.410e+00, 4....00, 8.610e+00, 8.810e+00, 9.010e+00, 9.210e+00, 9.410e+00,\n",
       "       9.610e+00, 9.810e+00, 1.001e+01])},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring=None, verbose=0)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# part 4\n",
    "#a)\n",
    "LSVC = LinearSVC()\n",
    "param_grid = {'C':np.arange(.01,10.2,.2)}\n",
    "\n",
    "SVC = GridSearchCV(LSVC, param_grid=param_grid, cv=5)\n",
    "SVC.fit(X_train_sc, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.01}\n",
      "LinearSVC(C=0.01, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "     verbose=0)\n"
     ]
    }
   ],
   "source": [
    "#b)\n",
    "print(SVC.best_params_)\n",
    "print(SVC.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#c)\n",
    "y_pred = SVC.best_estimator_.predict(X_test_sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "   asphalt        1.00      0.93      0.96        14\n",
      "  building        0.63      0.88      0.73        25\n",
      "       car        0.93      0.93      0.93        15\n",
      "  concrete        0.62      0.70      0.65        23\n",
      "     grass        0.73      0.83      0.77        29\n",
      "      pool        1.00      0.87      0.93        15\n",
      "    shadow        0.94      1.00      0.97        16\n",
      "      soil        1.00      0.07      0.13        14\n",
      "      tree        0.80      0.71      0.75        17\n",
      "\n",
      "avg / total       0.81      0.78      0.76       168\n",
      "\n",
      "[[13  0  0  0  0  0  1  0  0]\n",
      " [ 0 22  0  2  1  0  0  0  0]\n",
      " [ 0  1 14  0  0  0  0  0  0]\n",
      " [ 0  6  0 16  1  0  0  0  0]\n",
      " [ 0  0  0  2 24  0  0  0  3]\n",
      " [ 0  1  1  0  0 13  0  0  0]\n",
      " [ 0  0  0  0  0  0 16  0  0]\n",
      " [ 0  5  0  5  3  0  0  1  0]\n",
      " [ 0  0  0  1  4  0  0  0 12]]\n"
     ]
    }
   ],
   "source": [
    "#d)\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(confusion_matrix(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "   asphalt        0.95      0.93      0.94        45\n",
      "  building        0.81      0.91      0.86        97\n",
      "       car        1.00      0.90      0.95        21\n",
      "  concrete        0.87      0.86      0.86        93\n",
      "     grass        0.84      0.82      0.83        83\n",
      "      pool        1.00      0.86      0.92        14\n",
      "    shadow        0.88      0.98      0.93        45\n",
      "      soil        1.00      0.30      0.46        20\n",
      "      tree        0.85      0.91      0.88        89\n",
      "\n",
      "avg / total       0.87      0.87      0.86       507\n",
      "\n",
      "[[42  0  0  0  0  0  3  0  0]\n",
      " [ 1 88  0  7  0  0  1  0  0]\n",
      " [ 0  1 19  0  0  0  0  0  1]\n",
      " [ 0 12  0 80  1  0  0  0  0]\n",
      " [ 0  1  0  2 68  0  0  0 12]\n",
      " [ 0  1  0  0  1 12  0  0  0]\n",
      " [ 1  0  0  0  0  0 44  0  0]\n",
      " [ 0  5  0  3  5  0  0  6  1]\n",
      " [ 0  0  0  0  6  0  2  0 81]]\n"
     ]
    }
   ],
   "source": [
    "#d)\n",
    "y_pred_train = SVC.predict(X_train_sc)\n",
    "print(classification_report(y_train, y_pred_train))\n",
    "print(confusion_matrix(y_train, y_pred_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There does seem to be overfitting because our model returns an accuracy of 87% for our train data while the model return an accuracy of around 80% for our test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='poly',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'C': array([1.000e-02, 2.100e-01, 4.100e-01, 6.100e-01, 8.100e-01, 1.010e+00,\n",
       "       1.210e+00, 1.410e+00, 1.610e+00, 1.810e+00, 2.010e+00, 2.210e+00,\n",
       "       2.410e+00, 2.610e+00, 2.810e+00, 3.010e+00, 3.210e+00, 3.410e+00,\n",
       "       3.610e+00, 3.810e+00, 4.010e+00, 4.210e+00, 4.410e+00, 4.....010e+00, 9.210e+00, 9.410e+00,\n",
       "       9.610e+00, 9.810e+00, 1.001e+01]), 'degree': [2, 3, 4, 5, 6]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring=None, verbose=0)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Part 5)\n",
    "#a)\n",
    "param_grid = {'C':np.arange(.01,10.2,.2),\n",
    "             'degree': [2,3,4,5,6]}\n",
    "\n",
    "SVC = GridSearchCV(svm.SVC(kernel='poly'), param_grid=param_grid, cv=5)\n",
    "SVC.fit(X_train_sc, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 8.41, 'degree': 3}\n",
      "SVC(C=8.41, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='poly',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n"
     ]
    }
   ],
   "source": [
    "#b)\n",
    "print(SVC.best_params_)\n",
    "print(SVC.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#c)\n",
    "y_pred = SVC.best_estimator_.predict(X_test_sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "   asphalt        0.87      0.93      0.90        14\n",
      "  building        0.69      0.88      0.77        25\n",
      "       car        1.00      0.73      0.85        15\n",
      "  concrete        0.71      0.74      0.72        23\n",
      "     grass        0.72      0.90      0.80        29\n",
      "      pool        0.93      0.93      0.93        15\n",
      "    shadow        0.88      0.88      0.88        16\n",
      "      soil        0.25      0.07      0.11        14\n",
      "      tree        0.87      0.76      0.81        17\n",
      "\n",
      "avg / total       0.76      0.78      0.76       168\n",
      "\n",
      "[[13  0  0  0  0  0  1  0  0]\n",
      " [ 0 22  0  2  1  0  0  0  0]\n",
      " [ 0  2 11  0  0  1  0  1  0]\n",
      " [ 0  5  0 17  0  0  0  1  0]\n",
      " [ 0  0  0  0 26  0  0  1  2]\n",
      " [ 0  0  0  0  0 14  1  0  0]\n",
      " [ 2  0  0  0  0  0 14  0  0]\n",
      " [ 0  3  0  4  6  0  0  1  0]\n",
      " [ 0  0  0  1  3  0  0  0 13]]\n"
     ]
    }
   ],
   "source": [
    "#d)\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(confusion_matrix(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "   asphalt        1.00      1.00      1.00        45\n",
      "  building        0.98      1.00      0.99        97\n",
      "       car        1.00      0.95      0.98        21\n",
      "  concrete        1.00      0.98      0.99        93\n",
      "     grass        0.90      0.99      0.94        83\n",
      "      pool        1.00      0.93      0.96        14\n",
      "    shadow        1.00      1.00      1.00        45\n",
      "      soil        1.00      0.75      0.86        20\n",
      "      tree        1.00      0.99      0.99        89\n",
      "\n",
      "avg / total       0.98      0.98      0.98       507\n",
      "\n",
      "[[45  0  0  0  0  0  0  0  0]\n",
      " [ 0 97  0  0  0  0  0  0  0]\n",
      " [ 0  0 20  0  1  0  0  0  0]\n",
      " [ 0  1  0 91  1  0  0  0  0]\n",
      " [ 0  1  0  0 82  0  0  0  0]\n",
      " [ 0  0  0  0  1 13  0  0  0]\n",
      " [ 0  0  0  0  0  0 45  0  0]\n",
      " [ 0  0  0  0  5  0  0 15  0]\n",
      " [ 0  0  0  0  1  0  0  0 88]]\n"
     ]
    }
   ],
   "source": [
    "#e)\n",
    "y_pred_train = SVC.predict(X_train_sc)\n",
    "print(classification_report(y_train, y_pred_train))\n",
    "print(confusion_matrix(y_train, y_pred_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There does seem to be overfitting because our model returns an accuracy of 98% for our train data while the model return an accuracy of around 78% for our test data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'C': array([1.000e-02, 2.100e-01, 4.100e-01, 6.100e-01, 8.100e-01, 1.010e+00,\n",
       "       1.210e+00, 1.410e+00, 1.610e+00, 1.810e+00, 2.010e+00, 2.210e+00,\n",
       "       2.410e+00, 2.610e+00, 2.810e+00, 3.010e+00, 3.210e+00, 3.410e+00,\n",
       "       3.610e+00, 3.810e+00, 4.010e+00, 4.210e+00, 4.410e+00, 4.....010e+00, 9.210e+00, 9.410e+00,\n",
       "       9.610e+00, 9.810e+00, 1.001e+01]), 'degree': [2, 3, 4, 5, 6]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring=None, verbose=0)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Part 6)\n",
    "#a)\n",
    "param_grid = {'C':np.arange(.01,10.2,.2),\n",
    "             'degree': [2,3,4,5,6]}\n",
    "\n",
    "SVC = GridSearchCV(svm.SVC(kernel='rbf'), param_grid=param_grid, cv=5)\n",
    "SVC.fit(X_train_sc, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 5.21, 'degree': 2}\n",
      "SVC(C=5.21, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=2, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n"
     ]
    }
   ],
   "source": [
    "#b)\n",
    "print(SVC.best_params_)\n",
    "print(SVC.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#c)\n",
    "y_pred = SVC.best_estimator_.predict(X_test_sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "   asphalt        0.93      0.93      0.93        14\n",
      "  building        0.74      0.80      0.77        25\n",
      "       car        0.94      1.00      0.97        15\n",
      "  concrete        0.70      0.83      0.76        23\n",
      "     grass        0.83      0.86      0.85        29\n",
      "      pool        1.00      0.93      0.97        15\n",
      "    shadow        0.88      0.94      0.91        16\n",
      "      soil        0.80      0.29      0.42        14\n",
      "      tree        0.83      0.88      0.86        17\n",
      "\n",
      "avg / total       0.84      0.83      0.82       168\n",
      "\n",
      "[[13  0  0  0  0  0  1  0  0]\n",
      " [ 0 20  1  3  1  0  0  0  0]\n",
      " [ 0  0 15  0  0  0  0  0  0]\n",
      " [ 0  4  0 19  0  0  0  0  0]\n",
      " [ 0  0  0  0 25  0  0  1  3]\n",
      " [ 0  0  0  0  0 14  1  0  0]\n",
      " [ 1  0  0  0  0  0 15  0  0]\n",
      " [ 0  3  0  4  3  0  0  4  0]\n",
      " [ 0  0  0  1  1  0  0  0 15]]\n"
     ]
    }
   ],
   "source": [
    "#d)\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(confusion_matrix(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "   asphalt        1.00      1.00      1.00        45\n",
      "  building        0.98      1.00      0.99        97\n",
      "       car        1.00      1.00      1.00        21\n",
      "  concrete        1.00      0.99      0.99        93\n",
      "     grass        0.99      0.98      0.98        83\n",
      "      pool        1.00      1.00      1.00        14\n",
      "    shadow        1.00      1.00      1.00        45\n",
      "      soil        1.00      1.00      1.00        20\n",
      "      tree        0.99      0.99      0.99        89\n",
      "\n",
      "avg / total       0.99      0.99      0.99       507\n",
      "\n",
      "[[45  0  0  0  0  0  0  0  0]\n",
      " [ 0 97  0  0  0  0  0  0  0]\n",
      " [ 0  0 21  0  0  0  0  0  0]\n",
      " [ 0  1  0 92  0  0  0  0  0]\n",
      " [ 0  1  0  0 81  0  0  0  1]\n",
      " [ 0  0  0  0  0 14  0  0  0]\n",
      " [ 0  0  0  0  0  0 45  0  0]\n",
      " [ 0  0  0  0  0  0  0 20  0]\n",
      " [ 0  0  0  0  1  0  0  0 88]]\n"
     ]
    }
   ],
   "source": [
    "#e)\n",
    "y_pred_train = SVC.predict(X_train_sc)\n",
    "print(classification_report(y_train, y_pred_train))\n",
    "print(confusion_matrix(y_train, y_pred_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There does seem to be overfitting because our model returns an accuracy of 99% for our train data while the model return an accuracy of around 84% for our test data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7) Conceptual questions\n",
    "a) From the models run in steps 2-6, which performs the best based on the Classification Report? Support your reasoning with evidence around your test data\n",
    "The last model utilizing a SVC with a kernel of rbf created the best model when utilizing the classificaiton reports. We are able to make this claim due to the fact that the model returned the highest accuracy for our test data (88%) and our training data (99%).\n",
    "\n",
    "b) Compare models run for steps 4-6 where different kernels were used. What is the benefit of using a polynomial or rbf kernel over a linear kernel? What could be a downside of using a polynomial or rbf kernel? \n",
    "Utilizing a polynomial kernel or a rbf kernel allows us to create non linear hyperplanes which are otherwise impossible in a linear SVC. A potential downside to using a polynomial or rbf kernel is that those models typically take longer to run when compared to a linaer SVC model.\n",
    "\n",
    "c) Explain the 'C' parameter used in steps 4-6. What does a small C mean versus a large C in sklearn? Why is it important to use the 'C' parameter when fitting a model? \n",
    "The C parameter tells the SVM how much you want the model to avoid misclassification. If a larger C is inputted into the model, the model will look for a smaller-margin hyperplane if that hyperplane does a better job correctly classifying the data. For a small value of c, the optomizer will look for a larger margin seperating the hyperplane therfore allowing for misclassification. The C parameter is very important for SVC because you are telling the optimizer how leanient the model can be with misclassifications. \n",
    "\n",
    "d)Scaling our input data does not matter much for Random Forest, but it is a critical step for Support Vector Machines. Explain why this is such a critical step. Also, provide an example of a feature from this data set that could cause issues with our SVMs if not scaled.\n",
    "SVM optimizes based on the distribution of points. If there are parameters in the model with very different scales, and the data wasn't scaled, the SVM wouldn't be able to take into account the true distributions and variance of the data because it would be thrown off by the scale of the parameters. Before the data is scaled, both BrdIndx and Area have very different scales. When we scale these parameters to have a mean of 0 and variance of 1, it allows SVM to understand the true distribution of data between these two parameters. \n",
    "\n",
    "e) Describe conceptually what the purpose of a kernel is for Support Vector Machines.\n",
    "The purpose of a kernel is to create another dimension ontop of the dimensionality the data provides which allows for the model to create non linear hyperplanes onto the linear space of the data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
